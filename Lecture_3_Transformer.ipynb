{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAMIDSpiyalong/Gen-AI/blob/main/Lecture_3_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenE2varZEXc"
      },
      "source": [
        "# Transformers From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTSadDXiPQLm"
      },
      "source": [
        "This lab builds a sequence to sequence transformer, with encoder-decoder blocks from scratch for translation from Portuguese to English. Transformers excel at modeling sequential data, such as natural language. The datasets is from the TED Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAifCvd_Tth9"
      },
      "source": [
        "##Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg_2bsitTwAq"
      },
      "source": [
        "1. Understand and build the dot product self attention block, which is the key of the attention mechanism.\n",
        "2. Build a transformer from scratch with multiple attention heads.\n",
        "3. Train and evaluate the performance of such neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "JjJJyJTZYebt",
        "outputId": "c08a4c14-5d99-4230-8805-57c6a1df33b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.11.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "!pip install tensorflow==2.12.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_Qt8W1hJE_"
      },
      "source": [
        "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
        "\n",
        "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "8q9t4FmN96eN"
      },
      "outputs": [],
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
        "                               as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyTo86x5n1om",
        "outputId": "a08f0aeb-0dd8-48d8-ec42-e6cc9d0608ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Examples in Portuguese:\n",
            "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
            "mas e se estes fatores fossem ativos ?\n",
            "mas eles não tinham a curiosidade de me testar .\n",
            "\n",
            "> Examples in English:\n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
            "but what if it were active ?\n",
            "but they did n't test for curiosity .\n"
          ]
        }
      ],
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples in Portuguese:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Examples in English:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOe2oYkJE3ut"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCEKotqosGfq"
      },
      "source": [
        "Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a [token](https://developers.google.com/machine-learning/glossary#token) or token ID (a numeric representation).\n",
        "\n",
        "Tokenization is the process of breaking up text, into \"tokens\". Depending on the tokenizer, these tokens can represent sentence-pieces, words, subwords, or characters. To learn more about tokenization, visit [this guide](https://www.tensorflow.org/text/guide/tokenizers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KVBg5Q8tBk5z"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DYWukNFkGQN",
        "outputId": "a71bb576-4258-4853-cfc8-09971128fb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
            "The original string: Transformer is awesome.\n"
          ]
        }
      ],
      "source": [
        "sample_string = 'Transformer is awesome.'\n",
        "\n",
        "tokenized_string = tokenizer_en.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_en.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9KJWJjrsZ4Y"
      },
      "source": [
        "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2ntBxjkqK6",
        "outputId": "2deaeb7d-5722-4df5-b2af-9f33228f005e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|7915| ----> |T|\n",
            "|1248| ----> |ran|\n",
            "|7946| ----> |s|\n",
            "|7194| ----> |former |\n",
            "|13| ----> |is |\n",
            "|2799| ----> |awesome|\n",
            "|7877| ----> |.|\n"
          ]
        }
      ],
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('|{}| ----> |{}|'.format(ts, tokenizer_en.decode([ts])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FESLncJLFx-e"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGi4PoVakxdc"
      },
      "source": [
        "Add a start and end token to the input and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "UZwnPr4R055s"
      },
      "outputs": [],
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
        "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "\n",
        "  return lang1, lang2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx1sFbR-9fRs"
      },
      "source": [
        "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
        "\n",
        "* Graph tensors do not have a value.\n",
        "* In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Mah1cS-P70Iz"
      },
      "outputs": [],
      "source": [
        "def tf_encode(pt, en):\n",
        "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
        "  result_pt.set_shape([None])\n",
        "  result_en.set_shape([None])\n",
        "\n",
        "  return result_pt, result_en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrGp5Gek6Ql"
      },
      "source": [
        "Note: To keep this example small and relatively fast, drop examples with a length of over 20 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "2QEgbjntk6Yf"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "c081xPGv1CPI"
      },
      "outputs": [],
      "source": [
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9mk9AZdZ5bcS"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_examples.map(tf_encode)\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_dataset = val_examples.map(tf_encode)\n",
        "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fXvfYVfQr2n",
        "outputId": "9ea2b97e-fbb2-4f86-815c-1faf92c13f62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
              " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
              "        [8214,   95,  198, ...,    0,    0,    0],\n",
              "        [8214, 4479, 7990, ...,   97,    2, 8215],\n",
              "        ...,\n",
              "        [8214,  126,   70, ...,    0,    0,    0],\n",
              "        [8214,   22,  564, ...,    0,    0,    0],\n",
              "        [8214,   24,  215, ...,    0,    0,    0]])>,\n",
              " TensorShape([64, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "pt_batch, en_batch = next(iter(val_dataset))\n",
        "pt_batch, en_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDkTVv3KMJX_"
      },
      "source": [
        "We'll start with the **Multi-Head Self-Attention** layer since that's the most involved bit. Once we have that working, the rest should make sense as you go."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqX04fFXBdxy"
      },
      "source": [
        "## Multi-Head Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NAf9HP7RsQu"
      },
      "source": [
        "\n",
        "Inside each attention head is a **Scaled Dot Product Self-Attention** operation as we covered in the slides. Given *queries*, *keys*, and *values*, the operation returns a new \"mix\" of the values.\n",
        "\n",
        "$$Attention(Q, K, V) = softmax(\\frac{QK^T)}{\\sqrt{d_k}})V$$\n",
        "\n",
        "The following function implements this and also takes a mask to account for padding and for masking future tokens for decoding (i.e. **look-ahead mask**). We'll cover masking later in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "7hpO6cGEN7HK"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_HhsreXh3H"
      },
      "source": [
        "Suppose our *queries*, *keys*, and *values* are each a length of 3 with a dimension of 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB2cDybgX5LZ",
        "outputId": "3d493523-34ad-48da-cf1b-a61ad6d09bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries:\n",
            " [[0.9806526  0.5294707  0.08846168 0.3425922 ]\n",
            " [0.9910464  0.03192475 0.15577796 0.95880926]\n",
            " [0.9095092  0.73470753 0.42720568 0.8119622 ]]\n"
          ]
        }
      ],
      "source": [
        "seq_len = 3\n",
        "embed_dim = 4\n",
        "\n",
        "queries = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "keys = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "values = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "\n",
        "print(\"Queries:\\n\", queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuNdMuz5vb1c"
      },
      "source": [
        "This would be the self-attention output and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxKj56hNX5UO",
        "outputId": "e9395651-a58e-4ee8-a9d7-12f671bd0946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output\n",
            " tf.Tensor(\n",
            "[[0.23696409 0.70473623 0.5978477  0.9413505 ]\n",
            " [0.2381856  0.70620763 0.6010459  0.94117695]\n",
            " [0.24862812 0.7288328  0.61881196 0.9389543 ]], shape=(3, 4), dtype=float32) \n",
            "\n",
            "Weights\n",
            " tf.Tensor(\n",
            "[[0.4510512  0.24714395 0.3018048 ]\n",
            " [0.4552998  0.24144736 0.30325282]\n",
            " [0.5009048  0.22628222 0.27281293]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "output, attn_weights = scaled_dot_product_attention(queries, keys, values)\n",
        "\n",
        "print(\"Output\\n\", output, \"\\n\")\n",
        "print(\"Weights\\n\", attn_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "72DBX3F5X1UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "5oS1aQOJky-3",
        "outputId": "9132b3fa-aad8-4c30-90f5-e0a26ec75551"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def visualize_attention(attention_weights):\n",
        "    # Create heatmap using seaborn\n",
        "    sns.set(font_scale=1.2)\n",
        "    plt.figure()\n",
        "    ax = sns.heatmap(\n",
        "        attention_weights,\n",
        "        cmap=\"YlGnBu\",\n",
        "        linewidths=0.5,\n",
        "        annot=True,\n",
        "        xticklabels=True,\n",
        "        yticklabels=True,\n",
        "        cbar_kws={'label': 'Attention Weight'}\n",
        "    )\n",
        "    ax.set_title('Self-Attention Weights')\n",
        "    plt.xlabel('Input Tokens')\n",
        "    plt.ylabel('Output Tokens')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_attention(attn_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBm9jbpSN6-L"
      },
      "source": [
        "Now that we have a way to calculate self-attention, let's actually generate the input *queries*, *keys*, and *values* for multiple heads. It's easier to understand things this way and we can certainly code it this way as well. But we can also \"simulate\" different heads with a single query matrix, single key matrix, and single value matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJLyGtqbX3uW",
        "outputId": "dc561f9a-4d1a-41c5-a067-b35857e693bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of each head: 4\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "embed_dim = 12\n",
        "num_heads = 3\n",
        "head_dim = embed_dim // num_heads\n",
        "\n",
        "print(f\"Dimension of each head: {head_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDl37YzAf7bh"
      },
      "source": [
        "**Using separate weight matrices per head**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ_KoJq3fv-A"
      },
      "source": [
        "Suppose these are our input embeddings. Here we have a batch of 1 containing a sequence of length 3, with each element being a 12-dimensional embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NcX3KBrX3uW",
        "outputId": "e73c5e3a-0e14-49d7-c7a9-a70f87265279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  (1, 3, 12) \n",
            "\n",
            "Input:\n",
            " [[[0.4 0.3 0.4 0.2 0.2 0.2 0.  0.4 0.6 0.2 0.2 0.6]\n",
            "  [0.4 0.2 0.3 0.9 0.2 0.9 0.3 0.5 0.7 0.8 0.2 0.4]\n",
            "  [0.9 0.6 0.7 0.2 0.1 0.8 0.6 0.5 0.6 0.2 0.2 0.9]]]\n"
          ]
        }
      ],
      "source": [
        "x = np.random.rand(batch_size, seq_len, embed_dim).round(1).astype('float32')\n",
        "print(\"Input shape: \", x.shape, \"\\n\")\n",
        "print(\"Input:\\n\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvJicbp6f7pI"
      },
      "source": [
        "We'll declare three sets of *query* weights (one for each head), three sets of *key* weights, and three sets of *value* weights. Remember each weight matrix should have a dimension of $\\text{d}\\ \\text{x}\\ \\text{d/h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "8zdg7rqrX3uX"
      },
      "outputs": [],
      "source": [
        "# The query weights for each head.\n",
        "wq0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wq1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wq2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "\n",
        "# The key weights for each head.\n",
        "wk0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wk1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wk2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "\n",
        "# The value weights for each head.\n",
        "wv0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wv1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wv2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMRHZooX3uX",
        "outputId": "06477d2e-58c1-48b6-db64-a09e806eda14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three sets of query weights (one for each head):\n",
            "wq0:\n",
            " [[0.2 0.9 0.4 0.7]\n",
            " [0.4 0.1 0.2 0.2]\n",
            " [0.2 0.8 0.2 0.6]\n",
            " [0.5 0.4 0.1 0.9]\n",
            " [0.1 0.4 0.5 0.7]\n",
            " [0.4 0.4 0.6 0.1]\n",
            " [0.7 0.6 0.9 0.7]\n",
            " [0.6 0.4 0.9 0.1]\n",
            " [0.9 0.5 0.3 0.3]\n",
            " [0.2 0.3 0.5 0.8]\n",
            " [1.  0.7 0.  1. ]\n",
            " [0.3 0.4 0.1 0.2]]\n",
            "wq1:\n",
            " [[0.7 0.9 0.  0.2]\n",
            " [0.4 0.7 0.8 0.7]\n",
            " [0.6 0.5 0.1 0.6]\n",
            " [0.  0.8 0.2 0.7]\n",
            " [0.8 0.2 0.3 0.7]\n",
            " [0.6 0.2 1.  0.2]\n",
            " [0.9 0.5 0.2 0.5]\n",
            " [0.8 0.6 0.5 0.4]\n",
            " [0.5 0.  0.7 0.4]\n",
            " [0.5 0.7 0.8 1. ]\n",
            " [0.6 0.8 0.6 0.8]\n",
            " [0.4 0.8 0.1 0.4]]\n",
            "wq2:\n",
            " [[0.7 0.9 0.  0.2]\n",
            " [0.4 0.7 0.8 0.7]\n",
            " [0.6 0.5 0.1 0.6]\n",
            " [0.  0.8 0.2 0.7]\n",
            " [0.8 0.2 0.3 0.7]\n",
            " [0.6 0.2 1.  0.2]\n",
            " [0.9 0.5 0.2 0.5]\n",
            " [0.8 0.6 0.5 0.4]\n",
            " [0.5 0.  0.7 0.4]\n",
            " [0.5 0.7 0.8 1. ]\n",
            " [0.6 0.8 0.6 0.8]\n",
            " [0.4 0.8 0.1 0.4]]\n"
          ]
        }
      ],
      "source": [
        "print(\"The three sets of query weights (one for each head):\")\n",
        "print(\"wq0:\\n\", wq0)\n",
        "print(\"wq1:\\n\", wq1)\n",
        "print(\"wq2:\\n\", wq1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmwGKV9qgch-"
      },
      "source": [
        "We'll generate our *queries*, *keys*, and *values* for each head by multiplying our input by the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "NucbYNNSX3uX"
      },
      "outputs": [],
      "source": [
        "# Geneated queries, keys, and values for the first head.\n",
        "q0 = np.dot(x, wq0)\n",
        "k0 = np.dot(x, wk0)\n",
        "v0 = np.dot(x, wv0)\n",
        "\n",
        "# Geneated queries, keys, and values for the second head.\n",
        "q1 = np.dot(x, wq1)\n",
        "k1 = np.dot(x, wk1)\n",
        "v1 = np.dot(x, wv1)\n",
        "\n",
        "# Geneated queries, keys, and values for the third head.\n",
        "q2 = np.dot(x, wq2)\n",
        "k2 = np.dot(x, wk2)\n",
        "v2 = np.dot(x, wv2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIDiwWZ0gqhm"
      },
      "source": [
        "These are the resulting *query*, *key*, and *value* vectors for the first head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMcMmbkqX3uX",
        "outputId": "b5577147-70b4-4f99-9aa9-263b42d13350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q, K, and V for first head:\n",
            "\n",
            "q0 (1, 3, 4):\n",
            " [[[1.6800001 1.85      1.24      1.62     ]\n",
            "  [2.67      2.69      2.3600001 2.93     ]\n",
            "  [2.7600002 3.29      2.53      2.69     ]]] \n",
            "\n",
            "k0 (1, 3, 4):\n",
            " [[[2.3700001 1.9300001 1.5       1.9100001]\n",
            "  [3.67      2.8000002 2.73      2.67     ]\n",
            "  [4.55      3.        2.75      3.14     ]]] \n",
            "\n",
            "v0 (1, 3, 4):\n",
            " [[[2.8       1.6300001 2.05      1.8900001]\n",
            "  [3.7       2.16      2.97      2.75     ]\n",
            "  [4.48      2.76      3.5900002 2.94     ]]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Q, K, and V for first head:\\n\")\n",
        "\n",
        "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
        "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
        "print(f\"v0 {v0.shape}:\\n\", v0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw5CQ9i6qZDv"
      },
      "source": [
        "Now that we have our Q, K, V vectors, we can just pass them to our self-attention operation. Here we're calculating the output and attention weights for the first head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7tHIvXKX3uX",
        "outputId": "3f9cb7a1-e381-412a-ef23-b4cca168e50d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from first attention head:  tf.Tensor(\n",
            "[[[4.3032007 2.625287  3.4478455 2.8918545]\n",
            "  [4.3983564 2.697268  3.5250144 2.9198327]\n",
            "  [4.4017725 2.699874  3.527758  2.920752 ]]], shape=(1, 3, 4), dtype=float32) \n",
            "\n",
            "Attention weights from first head:  tf.Tensor(\n",
            "[[[7.9265526e-03 2.0959325e-01 7.8248018e-01]\n",
            "  [4.3664049e-04 1.0373135e-01 8.9583206e-01]\n",
            "  [3.0068459e-04 9.9644266e-02 9.0005511e-01]]], shape=(1, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "out0, attn_weights0 = scaled_dot_product_attention(q0, k0, v0)\n",
        "\n",
        "print(\"Output from first attention head: \", out0, \"\\n\")\n",
        "print(\"Attention weights from first head: \", attn_weights0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoYEXSm7qr_A"
      },
      "source": [
        "Here are the other two (attention weights are ignored)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otnqbaDSqpJ7",
        "outputId": "f2de73fb-fac0-4b7a-dc36-1bb041069e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from second attention head:  tf.Tensor(\n",
            "[[[3.1417913 3.016935  2.4482794 3.413989 ]\n",
            "  [3.0979733 3.0410235 2.4685628 3.412925 ]\n",
            "  [3.0687904 3.0531924 2.4788575 3.4097617]]], shape=(1, 3, 4), dtype=float32) \n",
            "\n",
            "Output from third attention head:  tf.Tensor(\n",
            "[[[2.9963849 3.1192305 2.254074  2.7340407]\n",
            "  [3.029502  3.1433072 2.2877948 2.747809 ]\n",
            "  [3.0336967 3.1460776 2.2925165 2.748907 ]]], shape=(1, 3, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "out1, _ = scaled_dot_product_attention(q1, k1, v1)\n",
        "out2, _ = scaled_dot_product_attention(q2, k2, v2)\n",
        "\n",
        "print(\"Output from second attention head: \", out1, \"\\n\")\n",
        "print(\"Output from third attention head: \", out2,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOV717bqX3uX"
      },
      "source": [
        "As we covered in the slides, once we have each head's output, we concatenate them and then put them through a linear layer for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmSv5trtt2v9",
        "outputId": "d1f07ac7-a2be-4336-d822-8aa3e3ce7468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined output from all heads (1, 3, 12):\n",
            "[[[4.3032007 2.625287  3.4478455 2.8918545 3.1417913 3.016935  2.4482794\n",
            "   3.413989  2.9963849 3.1192305 2.254074  2.7340407]\n",
            "  [4.3983564 2.697268  3.5250144 2.9198327 3.0979733 3.0410235 2.4685628\n",
            "   3.412925  3.029502  3.1433072 2.2877948 2.747809 ]\n",
            "  [4.4017725 2.699874  3.527758  2.920752  3.0687904 3.0531924 2.4788575\n",
            "   3.4097617 3.0336967 3.1460776 2.2925165 2.748907 ]]]\n"
          ]
        }
      ],
      "source": [
        "combined_out_a = np.concatenate((out0, out1, out2), axis=-1)\n",
        "print(f\"Combined output from all heads {combined_out_a.shape}:\")\n",
        "print(combined_out_a)\n",
        "\n",
        "# The final step would be to run combined_out_a through a linear/dense layer\n",
        "# for further processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.\n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "BSV3PPKsYecw"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu94p-_-2_BX",
        "outputId": "13726671-02f4-44b9-a8d1-0bdce57e2559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 3, 4]), TensorShape([2, 2, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "temp_mha = MultiHeadAttention(d_model=4, num_heads=2)\n",
        "y = tf.random.uniform((2, 3, 4))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(v=y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn[0][0]"
      ],
      "metadata": {
        "id": "KCf03zinNsHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932e6447-5026-4d63-a141-822d12d5c20e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0.20697848, 0.4437654 , 0.34925598],\n",
              "       [0.28916943, 0.3615377 , 0.34929296],\n",
              "       [0.30114362, 0.353034  , 0.3458224 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.\n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "WhIOZjMNKujn"
      },
      "outputs": [],
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1kLCla68EloE",
        "outputId": "583eae66-0081-4cab-b3d6-eb5829cff431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10, 512)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pos_encoding = positional_encoding(10, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "U2i8-e1s8ti9"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7BYeBCNvi7n",
        "outputId": "5f9ba69e-805b-4510-ae71-5c12ba2c378c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fG5gqr1nXkPM"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "dVxS8OPI9uI0"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxKGuXxaBeeE",
        "outputId": "26c035a9-35a8-45b4-848a-001658b10fad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "x = tf.random.uniform((3, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ET7xLt0yCT6Z"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mytb1lPyOHLB",
        "outputId": "8a8b08db-99f1-4c14-8f07-38965992dd7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "sample_ffn = point_wise_feed_forward_network(3, 4)\n",
        "sample_ffn(tf.random.uniform((64, 3, 4))).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ffn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF6fNkn7yzvJ",
        "outputId": "0564ea7b-d8b0-44c1-a57b-0a6bb355d235"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_85 (Dense)            (64, 3, 4)                20        \n",
            "                                                                 \n",
            " dense_86 (Dense)            (64, 3, 3)                15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35\n",
            "Trainable params: 35\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask)\n",
        "2.    Point wise feed forward networks.\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzZRXdO0mI48",
        "outputId": "7dd1f687-3e0f-4c67-bae5-2ae07b97e148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(4, 2, 7)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 3, 4)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne2Bqx8k71l0",
        "outputId": "0058dfa3-b9b2-4917-9179-a76bd22a1f00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(4, 2, 7)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 3, 4)), sample_encoder_layer_output,\n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BnquLx56zZdk"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPIHBjvsCPYW"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QG9nueFQKXx",
        "outputId": "d8e58b6f-655d-45e2-c2e0-e6e8fdea661a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 3, 4)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder = Encoder(num_layers=1, d_model=4, num_heads=2,\n",
        "                         dff=7, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eb=tf.keras.layers.Embedding(800, 4)\n",
        "eb(622)"
      ],
      "metadata": {
        "id": "lLwqNG9_zYy9",
        "outputId": "5df541bd-be78-4809-d7e9-75aa48127e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.02155962, -0.04306699, -0.00720134,  0.03320589], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "na3WMc6-7n-G"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1jXoAMRZyvu",
        "outputId": "d0104aef-3461-49d7-8d8a-67811a83a861"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 3, 4]), TensorShape([64, 2, 3, 24]))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=4, num_heads=2,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FEnC2EYpzzvc"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ4fbQcIkHW1",
        "outputId": "a9334c3f-ec0f-4d7e-fd48-e99ebb6e2964"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512, 3, 8000])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=4, num_heads=2, dff=7,\n",
        "    input_vocab_size=8500, target_vocab_size=8000,\n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzF0uyBTzhOG",
        "outputId": "4c0a4eef-e69a-4164-e27e-c07908622637"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_3 (Encoder)         multiple                  34326     \n",
            "                                                                 \n",
            " decoder_3 (Decoder)         multiple                  32502     \n",
            "                                                                 \n",
            " dense_161 (Dense)           multiple                  40000     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 106,828\n",
            "Trainable params: 106,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bP5fk79FzgN5"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced.\n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "lnJn5SLA2ahP"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "8a_CTrcQzJ6U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "DwESUUznx0Ke"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "MlhsJMm0TW_B"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "67oqVHiT0Eiu"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "phlyxMnm-Tpx"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ZOJUSB1T8GjM"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "hNhuYfllndLZ"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
        "\n",
        "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
        "\n",
        "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
        "\n",
        "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "LKpoA6q1sJFj"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "iJwmp9OE29oj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "Portuguese is used as the input language and English is the target language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbvmaKNiznHZ"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
        "                                                train_loss.result(),\n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5buvMlnvyrFm"
      },
      "outputs": [],
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_pt.vocab_size]\n",
        "  end_token = [tokenizer_pt.vocab_size + 1]\n",
        "\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [tokenizer_en.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer_en.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"este é um problema que temos que resolver.\"\n",
        "\n",
        "result, attention_weights = evaluate(sentence)"
      ],
      "metadata": {
        "id": "amDqKFOYOp6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "iUYysnkIR_-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.keys()"
      ],
      "metadata": {
        "id": "EmYL0oqFOp_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU2_yG_vBGza"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer_en.decode([i for i in result\n",
        "                                            if i < tokenizer_en.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z0Ws0EN9RaLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsxrAlvFG8SZ"
      },
      "outputs": [],
      "source": [
        "translate(\"este é um problema que temos que resolver.\")\n",
        "print (\"Real translation: this is a problem we have to solve .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EH5y_aqI4t1"
      },
      "outputs": [],
      "source": [
        "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
        "print (\"Real translation: and my neighboring homes heard about this idea .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-hVCTSUMlkb"
      },
      "outputs": [],
      "source": [
        "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
        "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-kFyiOLH0xg"
      },
      "outputs": [],
      "source": [
        "translate(\"este é o primeiro livro que eu fiz.\")\n",
        "print (\"Real translation: this is the first book i've ever done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ooPd1XHTG6Wy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "s_qNSzzyaCbD"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}