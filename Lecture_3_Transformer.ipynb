{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAMIDSpiyalong/Gen-AI/blob/main/Lecture_3_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenE2varZEXc"
      },
      "source": [
        "# Transformers From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTSadDXiPQLm"
      },
      "source": [
        "This lab builds a sequence to sequence transformer, with encoder-decoder blocks from scratch for translation from Portuguese to English. Transformers excel at modeling sequential data, such as natural language. The datasets is from the TED Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAifCvd_Tth9"
      },
      "source": [
        "##Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg_2bsitTwAq"
      },
      "source": [
        "1. Understand and build the dot product self attention block, which is the key of the attention mechanism.\n",
        "2. Build a transformer from scratch with multiple attention heads.\n",
        "3. Train and evaluate the performance of such neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "JjJJyJTZYebt",
        "outputId": "7a23a679-29e5-454a-810c-42b6e4b03223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.12.0 -q\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_Qt8W1hJE_"
      },
      "source": [
        "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
        "\n",
        "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "8q9t4FmN96eN"
      },
      "outputs": [],
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
        "                               as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyTo86x5n1om",
        "outputId": "f7742b5b-fdc4-4665-ae2d-3e1527509c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Examples in Portuguese:\n",
            "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
            "mas e se estes fatores fossem ativos ?\n",
            "mas eles não tinham a curiosidade de me testar .\n",
            "\n",
            "> Examples in English:\n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
            "but what if it were active ?\n",
            "but they did n't test for curiosity .\n"
          ]
        }
      ],
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples in Portuguese:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Examples in English:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOe2oYkJE3ut"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCEKotqosGfq"
      },
      "source": [
        "Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a [token](https://developers.google.com/machine-learning/glossary#token) or token ID (a numeric representation).\n",
        "\n",
        "Tokenization is the process of breaking up text, into \"tokens\". Depending on the tokenizer, these tokens can represent sentence-pieces, words, subwords, or characters. To learn more about tokenization, visit [this guide](https://www.tensorflow.org/text/guide/tokenizers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "KVBg5Q8tBk5z"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DYWukNFkGQN",
        "outputId": "2455ecf6-2fd1-4d36-f288-8cd7b6f0bdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
            "The original string: Transformer is awesome.\n"
          ]
        }
      ],
      "source": [
        "sample_string = 'Transformer is awesome.'\n",
        "\n",
        "tokenized_string = tokenizer_en.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_en.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9KJWJjrsZ4Y"
      },
      "source": [
        "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2ntBxjkqK6",
        "outputId": "2795c1dc-c9bf-4f58-ad05-e9307a4dc412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|7915| ----> |T|\n",
            "|1248| ----> |ran|\n",
            "|7946| ----> |s|\n",
            "|7194| ----> |former |\n",
            "|13| ----> |is |\n",
            "|2799| ----> |awesome|\n",
            "|7877| ----> |.|\n"
          ]
        }
      ],
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('|{}| ----> |{}|'.format(ts, tokenizer_en.decode([ts])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FESLncJLFx-e"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGi4PoVakxdc"
      },
      "source": [
        "Add a start and end token to the input and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "UZwnPr4R055s"
      },
      "outputs": [],
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
        "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "\n",
        "  return lang1, lang2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx1sFbR-9fRs"
      },
      "source": [
        "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
        "\n",
        "* Graph tensors do not have a value.\n",
        "* In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Mah1cS-P70Iz"
      },
      "outputs": [],
      "source": [
        "def tf_encode(pt, en):\n",
        "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
        "  result_pt.set_shape([None])\n",
        "  result_en.set_shape([None])\n",
        "\n",
        "  return result_pt, result_en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrGp5Gek6Ql"
      },
      "source": [
        "Note: To keep this example small and relatively fast, drop examples with a length of over 20 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "2QEgbjntk6Yf"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "c081xPGv1CPI"
      },
      "outputs": [],
      "source": [
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "9mk9AZdZ5bcS"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_examples.map(tf_encode)\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_dataset = val_examples.map(tf_encode)\n",
        "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fXvfYVfQr2n",
        "outputId": "170feef9-1443-493f-ff1e-52025fc1f915"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128, 20), dtype=int64, numpy=\n",
              " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
              "        [8214,   95,  198, ...,    0,    0,    0],\n",
              "        [8214, 4479, 7990, ...,   97,    2, 8215],\n",
              "        ...,\n",
              "        [8214,    7, 1015, ...,    0,    0,    0],\n",
              "        [8214,   47,   13, ...,    0,    0,    0],\n",
              "        [8214, 1384,    5, ...,    0,    0,    0]])>,\n",
              " TensorShape([128, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "pt_batch, en_batch = next(iter(val_dataset))\n",
        "pt_batch, en_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDkTVv3KMJX_"
      },
      "source": [
        "We'll start with the **Multi-Head Self-Attention** layer since that's the most involved bit. Once we have that working, the rest should make sense as you go."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqX04fFXBdxy"
      },
      "source": [
        "## Multi-Head Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NAf9HP7RsQu"
      },
      "source": [
        "\n",
        "Inside each attention head is a **Scaled Dot Product Self-Attention** operation as we covered in the slides. Given *queries*, *keys*, and *values*, the operation returns a new \"mix\" of the values.\n",
        "\n",
        "$$Attention(Q, K, V) = softmax(\\frac{QK^T)}{\\sqrt{d_k}})V$$\n",
        "\n",
        "The following function implements this and also takes a mask to account for padding and for masking future tokens for decoding (i.e. **look-ahead mask**). We'll cover masking later in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "7hpO6cGEN7HK"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_HhsreXh3H"
      },
      "source": [
        "Suppose our *queries*, *keys*, and *values* are each a length of 3 with a dimension of 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB2cDybgX5LZ",
        "outputId": "19a5bf67-f3b5-4609-e6ef-5264b7d0a833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries:\n",
            " [[0.9923237  0.21823208 0.6316476  0.65908   ]\n",
            " [0.75823015 0.06993361 0.540286   0.31330198]\n",
            " [0.8839524  0.77139467 0.25222293 0.5462441 ]]\n"
          ]
        }
      ],
      "source": [
        "seq_len = 3\n",
        "embed_dim = 4\n",
        "\n",
        "queries = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "keys = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "values = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "\n",
        "print(\"Queries:\\n\", queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuNdMuz5vb1c"
      },
      "source": [
        "This would be the self-attention output and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxKj56hNX5UO",
        "outputId": "4fcd64c1-1b90-47d0-f97f-0e5a2d0ac31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output\n",
            " tf.Tensor(\n",
            "[[0.4366843  0.8300302  0.53221244 0.5659942 ]\n",
            " [0.43549252 0.82489944 0.53771144 0.5581338 ]\n",
            " [0.3984319  0.83293355 0.53571457 0.54995894]], shape=(3, 4), dtype=float32) \n",
            "\n",
            "Weights\n",
            " tf.Tensor(\n",
            "[[0.33611903 0.3098051  0.35407588]\n",
            " [0.32974046 0.32455665 0.34570283]\n",
            " [0.28977373 0.30393857 0.40628764]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "output, attn_weights = scaled_dot_product_attention(queries, keys, values)\n",
        "\n",
        "print(\"Output\\n\", output, \"\\n\")\n",
        "print(\"Weights\\n\", attn_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "72DBX3F5X1UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "5oS1aQOJky-3",
        "outputId": "8649ff71-a4fa-4924-8971-3f87cce9a5e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def visualize_attention(attention_weights):\n",
        "    # Create heatmap using seaborn\n",
        "    sns.set(font_scale=1.2)\n",
        "    plt.figure()\n",
        "    ax = sns.heatmap(\n",
        "        attention_weights,\n",
        "        cmap=\"YlGnBu\",\n",
        "        linewidths=0.5,\n",
        "        annot=True,\n",
        "        xticklabels=True,\n",
        "        yticklabels=True,\n",
        "        cbar_kws={'label': 'Attention Weight'}\n",
        "    )\n",
        "    ax.set_title('Self-Attention Weights')\n",
        "    plt.xlabel('Input Tokens')\n",
        "    plt.ylabel('Output Tokens')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_attention(attn_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBm9jbpSN6-L"
      },
      "source": [
        "Now that we have a way to calculate self-attention, let's actually generate the input *queries*, *keys*, and *values* for multiple heads. It's easier to understand things this way and we can certainly code it this way as well. But we can also \"simulate\" different heads with a single query matrix, single key matrix, and single value matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJLyGtqbX3uW",
        "outputId": "b4d83e76-87c4-4641-fbe4-8cc6834b3a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of each head: 4\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "embed_dim = 12\n",
        "num_heads = 3\n",
        "head_dim = embed_dim // num_heads\n",
        "\n",
        "print(f\"Dimension of each head: {head_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDl37YzAf7bh"
      },
      "source": [
        "**Using separate weight matrices per head**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ_KoJq3fv-A"
      },
      "source": [
        "Suppose these are our input embeddings. Here we have a batch of 1 containing a sequence of length 3, with each element being a 12-dimensional embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NcX3KBrX3uW",
        "outputId": "d9b14450-b0cd-4f22-b25d-f4d20529b650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:  (1, 3, 12) \n",
            "\n",
            "Input:\n",
            " [[[0.1 0.5 0.3 0.9 0.  0.6 0.3 1.  0.5 0.1 0.4 0.4]\n",
            "  [0.4 0.  0.8 0.4 0.5 1.  0.1 0.1 0.3 0.4 0.2 0.9]\n",
            "  [0.6 1.  0.9 0.1 0.7 0.1 0.7 0.2 0.6 1.  0.2 0.3]]]\n"
          ]
        }
      ],
      "source": [
        "x = np.random.rand(batch_size, seq_len, embed_dim).round(1).astype('float32')\n",
        "print(\"Input shape: \", x.shape, \"\\n\")\n",
        "print(\"Input:\\n\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvJicbp6f7pI"
      },
      "source": [
        "We'll declare three sets of *query* weights (one for each head), three sets of *key* weights, and three sets of *value* weights. Remember each weight matrix should have a dimension of $\\text{d}\\ \\text{x}\\ \\text{d/h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "8zdg7rqrX3uX"
      },
      "outputs": [],
      "source": [
        "# The query weights for each head.\n",
        "wq0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wq1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wq2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "\n",
        "# The key weights for each head.\n",
        "wk0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wk1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wk2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "\n",
        "# The value weights for each head.\n",
        "wv0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wv1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wv2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMRHZooX3uX",
        "outputId": "0e6e2909-cee7-46de-f4fb-c740611e6af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three sets of query weights (one for each head):\n",
            "wq0:\n",
            " [[0.9 0.1 0.6 0.1]\n",
            " [0.3 0.6 0.6 0.5]\n",
            " [1.  0.6 0.7 0.3]\n",
            " [0.4 0.6 0.2 0.9]\n",
            " [0.6 0.9 0.9 0. ]\n",
            " [0.2 0.2 0.1 0.9]\n",
            " [0.1 0.1 0.7 0.9]\n",
            " [0.6 0.4 0.4 0.2]\n",
            " [0.8 0.5 0.4 0.5]\n",
            " [0.6 0.3 0.7 0.8]\n",
            " [0.3 0.6 0.4 0.9]\n",
            " [0.3 0.6 1.  0.7]]\n",
            "wq1:\n",
            " [[0.9 0.4 0.  0.5]\n",
            " [1.  0.5 0.7 0.2]\n",
            " [0.3 0.8 0.3 0.4]\n",
            " [0.7 0.  0.6 0.2]\n",
            " [0.5 0.4 0.1 0.1]\n",
            " [0.1 0.7 0.6 0.2]\n",
            " [0.8 0.9 0.8 0.8]\n",
            " [0.4 1.  0.2 0.1]\n",
            " [0.  0.3 0.5 0.6]\n",
            " [0.9 0.1 0.7 0.3]\n",
            " [0.4 0.8 0.2 0.8]\n",
            " [0.7 0.9 0.1 0.8]]\n",
            "wq2:\n",
            " [[0.9 0.4 0.  0.5]\n",
            " [1.  0.5 0.7 0.2]\n",
            " [0.3 0.8 0.3 0.4]\n",
            " [0.7 0.  0.6 0.2]\n",
            " [0.5 0.4 0.1 0.1]\n",
            " [0.1 0.7 0.6 0.2]\n",
            " [0.8 0.9 0.8 0.8]\n",
            " [0.4 1.  0.2 0.1]\n",
            " [0.  0.3 0.5 0.6]\n",
            " [0.9 0.1 0.7 0.3]\n",
            " [0.4 0.8 0.2 0.8]\n",
            " [0.7 0.9 0.1 0.8]]\n"
          ]
        }
      ],
      "source": [
        "print(\"The three sets of query weights (one for each head):\")\n",
        "print(\"wq0:\\n\", wq0)\n",
        "print(\"wq1:\\n\", wq1)\n",
        "print(\"wq2:\\n\", wq1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmwGKV9qgch-"
      },
      "source": [
        "We'll generate our *queries*, *keys*, and *values* for each head by multiplying our input by the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "NucbYNNSX3uX"
      },
      "outputs": [],
      "source": [
        "# Geneated queries, keys, and values for the first head.\n",
        "q0 = np.dot(x, wq0)\n",
        "k0 = np.dot(x, wk0)\n",
        "v0 = np.dot(x, wv0)\n",
        "\n",
        "# Geneated queries, keys, and values for the second head.\n",
        "q1 = np.dot(x, wq1)\n",
        "k1 = np.dot(x, wk1)\n",
        "v1 = np.dot(x, wv1)\n",
        "\n",
        "# Geneated queries, keys, and values for the third head.\n",
        "q2 = np.dot(x, wq2)\n",
        "k2 = np.dot(x, wk2)\n",
        "v2 = np.dot(x, wv2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIDiwWZ0gqhm"
      },
      "source": [
        "These are the resulting *query*, *key*, and *value* vectors for the first head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMcMmbkqX3uX",
        "outputId": "5f4ab1f1-306a-4e32-cddb-a4bebdf75497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q, K, and V for first head:\n",
            "\n",
            "q0 (1, 3, 4):\n",
            " [[[2.35      2.3400002 2.25      3.14     ]\n",
            "  [2.7       2.39      2.92      2.93     ]\n",
            "  [3.64      2.96      4.14      3.17     ]]] \n",
            "\n",
            "k0 (1, 3, 4):\n",
            " [[[3.36      2.42      2.8700001 2.58     ]\n",
            "  [2.65      2.31      3.6699998 2.3400002]\n",
            "  [3.21      3.86      4.41      2.13     ]]] \n",
            "\n",
            "v0 (1, 3, 4):\n",
            " [[[2.34      3.14      2.16      2.3100002]\n",
            "  [2.43      3.13      2.47      2.6299999]\n",
            "  [3.56      3.65      2.89      2.91     ]]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Q, K, and V for first head:\\n\")\n",
        "\n",
        "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
        "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
        "print(f\"v0 {v0.shape}:\\n\", v0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw5CQ9i6qZDv"
      },
      "source": [
        "Now that we have our Q, K, V vectors, we can just pass them to our self-attention operation. Here we're calculating the output and attention weights for the first head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7tHIvXKX3uX",
        "outputId": "1eb897bb-b49d-4fb9-9a87-f0f6447c5150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from first attention head:  tf.Tensor(\n",
            "[[[3.4233496 3.5907235 2.8198094 2.8552558]\n",
            "  [3.473799  3.6124637 2.8464975 2.8763006]\n",
            "  [3.532247  3.6378882 2.876139  2.899306 ]]], shape=(1, 3, 4), dtype=float32) \n",
            "\n",
            "Attention weights from first head:  tf.Tensor(\n",
            "[[[0.07015108 0.04519116 0.88465774]\n",
            "  [0.04145149 0.03153108 0.92701745]\n",
            "  [0.01282231 0.01071651 0.9764612 ]]], shape=(1, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "out0, attn_weights0 = scaled_dot_product_attention(q0, k0, v0)\n",
        "\n",
        "print(\"Output from first attention head: \", out0, \"\\n\")\n",
        "print(\"Attention weights from first head: \", attn_weights0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoYEXSm7qr_A"
      },
      "source": [
        "Here are the other two (attention weights are ignored)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otnqbaDSqpJ7",
        "outputId": "f9fb1d35-f1db-4b46-dcfb-526e39355d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from second attention head:  tf.Tensor(\n",
            "[[[3.5809238 2.969889  3.0187228 3.0839522]\n",
            "  [3.5653853 2.953926  3.0193603 3.0775683]\n",
            "  [3.6584826 3.0427072 3.0348375 3.1039925]]], shape=(1, 3, 4), dtype=float32) \n",
            "\n",
            "Output from third attention head:  tf.Tensor(\n",
            "[[[3.0135348 3.1250916 2.4828892 2.215112 ]\n",
            "  [3.0918388 3.1722445 2.4658492 2.2454188]\n",
            "  [3.2054698 3.2431772 2.4423296 2.2916973]]], shape=(1, 3, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "out1, _ = scaled_dot_product_attention(q1, k1, v1)\n",
        "out2, _ = scaled_dot_product_attention(q2, k2, v2)\n",
        "\n",
        "print(\"Output from second attention head: \", out1, \"\\n\")\n",
        "print(\"Output from third attention head: \", out2,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOV717bqX3uX"
      },
      "source": [
        "As we covered in the slides, once we have each head's output, we concatenate them and then put them through a linear layer for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmSv5trtt2v9",
        "outputId": "a77d7830-a822-41a5-9b9b-98f8f1943398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined output from all heads (1, 3, 12):\n",
            "[[[3.4233496 3.5907235 2.8198094 2.8552558 3.5809238 2.969889  3.0187228\n",
            "   3.0839522 3.0135348 3.1250916 2.4828892 2.215112 ]\n",
            "  [3.473799  3.6124637 2.8464975 2.8763006 3.5653853 2.953926  3.0193603\n",
            "   3.0775683 3.0918388 3.1722445 2.4658492 2.2454188]\n",
            "  [3.532247  3.6378882 2.876139  2.899306  3.6584826 3.0427072 3.0348375\n",
            "   3.1039925 3.2054698 3.2431772 2.4423296 2.2916973]]]\n"
          ]
        }
      ],
      "source": [
        "combined_out_a = np.concatenate((out0, out1, out2), axis=-1)\n",
        "print(f\"Combined output from all heads {combined_out_a.shape}:\")\n",
        "print(combined_out_a)\n",
        "\n",
        "# The final step would be to run combined_out_a through a linear/dense layer\n",
        "# for further processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.\n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "BSV3PPKsYecw"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu94p-_-2_BX",
        "outputId": "7c0d484e-340e-44c4-8eba-9ca904e46c03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 3, 4]), TensorShape([2, 2, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "temp_mha = MultiHeadAttention(d_model=4, num_heads=2)\n",
        "y = tf.random.uniform((2, 3, 4))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(v=y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn[0][0]"
      ],
      "metadata": {
        "id": "KCf03zinNsHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac537bc-b670-41c6-bfa2-ae38c77fdb46"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0.33160132, 0.33501938, 0.33337927],\n",
              "       [0.34133017, 0.3239819 , 0.33468783],\n",
              "       [0.3308343 , 0.32879376, 0.34037188]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.\n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "WhIOZjMNKujn"
      },
      "outputs": [],
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1kLCla68EloE",
        "outputId": "a136602b-22ea-47de-ed13-9a60537eda98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10, 512)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pos_encoding = positional_encoding(10, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "U2i8-e1s8ti9"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7BYeBCNvi7n",
        "outputId": "131121f7-7043-4599-f5e9-41ce7c6ff56f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fG5gqr1nXkPM"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "dVxS8OPI9uI0"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxKGuXxaBeeE",
        "outputId": "a11a09c1-5664-4b0f-8940-d5de06d715fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "x = tf.random.uniform((3, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ET7xLt0yCT6Z"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mytb1lPyOHLB",
        "outputId": "cfc2d476-0a81-427a-f4d8-1b0d0c4e4c51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "sample_ffn = point_wise_feed_forward_network(3, 4)\n",
        "sample_ffn(tf.random.uniform((64, 3, 4))).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ffn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF6fNkn7yzvJ",
        "outputId": "2f55d886-09b2-4258-e702-a867fc96a243"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_150 (Dense)           (64, 3, 4)                20        \n",
            "                                                                 \n",
            " dense_151 (Dense)           (64, 3, 3)                15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35\n",
            "Trainable params: 35\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask)\n",
        "2.    Point wise feed forward networks.\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzZRXdO0mI48",
        "outputId": "d2750f60-7007-4c43-d3b7-1e9542552466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(4, 2, 7)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 3, 4)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne2Bqx8k71l0",
        "outputId": "50ca8c9f-3824-49b5-d1bd-4b64819c59f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(4, 2, 7)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 3, 4)), sample_encoder_layer_output,\n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BnquLx56zZdk"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPIHBjvsCPYW"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QG9nueFQKXx",
        "outputId": "a7a60639-b551-408e-8000-ab948b7e5943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 3, 4)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder = Encoder(num_layers=1, d_model=4, num_heads=2,\n",
        "                         dff=7, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eb=tf.keras.layers.Embedding(800, 4)\n",
        "eb(622)"
      ],
      "metadata": {
        "id": "lLwqNG9_zYy9",
        "outputId": "c50c6c1c-7bcd-4079-aaf4-3135acacd811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.0300833 ,  0.02408404, -0.01519816,  0.03299591], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "na3WMc6-7n-G"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1jXoAMRZyvu",
        "outputId": "25da021c-4ca8-4504-9a0e-01d280c94277"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 3, 4]), TensorShape([64, 2, 3, 24]))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=4, num_heads=2,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FEnC2EYpzzvc"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ4fbQcIkHW1",
        "outputId": "2f0e6c21-47ac-44d1-dc4a-38e56119c315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512, 3, 8000])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=4, num_heads=2, dff=7,\n",
        "    input_vocab_size=8500, target_vocab_size=8000,\n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzF0uyBTzhOG",
        "outputId": "219a2d36-051a-4f5b-c353-02cf8ce7538a"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_4 (Encoder)         multiple                  34326     \n",
            "                                                                 \n",
            " decoder_4 (Decoder)         multiple                  32502     \n",
            "                                                                 \n",
            " dense_226 (Dense)           multiple                  40000     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 106,828\n",
            "Trainable params: 106,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bP5fk79FzgN5"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced.\n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "lnJn5SLA2ahP"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "8a_CTrcQzJ6U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.001, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "DwESUUznx0Ke"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "MlhsJMm0TW_B"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "67oqVHiT0Eiu"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "phlyxMnm-Tpx"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ZOJUSB1T8GjM"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "hNhuYfllndLZ"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
        "\n",
        "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
        "\n",
        "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
        "\n",
        "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "LKpoA6q1sJFj"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "iJwmp9OE29oj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "Portuguese is used as the input language and English is the target language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbvmaKNiznHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3af4f71-df04-4d48-db7e-40d6e3b1a851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 8.9985 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 6.9677 Accuracy 0.0517\n",
            "Epoch 1 Batch 100 Loss 6.4413 Accuracy 0.0758\n",
            "Epoch 1 Batch 150 Loss 6.1045 Accuracy 0.0938\n",
            "Epoch 1 Batch 200 Loss 5.8440 Accuracy 0.1105\n",
            "Epoch 1 Loss 5.7998 Accuracy 0.1132\n",
            "Time taken for 1 epoch: 781.6297881603241 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.7500 Accuracy 0.1711\n",
            "Epoch 2 Batch 50 Loss 4.7136 Accuracy 0.1823\n",
            "Epoch 2 Batch 100 Loss 4.6551 Accuracy 0.1865\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
        "                                                train_loss.result(),\n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5buvMlnvyrFm"
      },
      "outputs": [],
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_pt.vocab_size]\n",
        "  end_token = [tokenizer_pt.vocab_size + 1]\n",
        "\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [tokenizer_en.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer_en.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"este é um problema que temos que resolver.\"\n",
        "\n",
        "result, attention_weights = evaluate(sentence)"
      ],
      "metadata": {
        "id": "amDqKFOYOp6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "iUYysnkIR_-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.keys()"
      ],
      "metadata": {
        "id": "EmYL0oqFOp_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU2_yG_vBGza"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer_en.decode([i for i in result\n",
        "                                            if i < tokenizer_en.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z0Ws0EN9RaLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsxrAlvFG8SZ"
      },
      "outputs": [],
      "source": [
        "translate(\"este é um problema que temos que resolver.\")\n",
        "print (\"Real translation: this is a problem we have to solve .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EH5y_aqI4t1"
      },
      "outputs": [],
      "source": [
        "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
        "print (\"Real translation: and my neighboring homes heard about this idea .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-hVCTSUMlkb"
      },
      "outputs": [],
      "source": [
        "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
        "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-kFyiOLH0xg"
      },
      "outputs": [],
      "source": [
        "translate(\"este é o primeiro livro que eu fiz.\")\n",
        "print (\"Real translation: this is the first book i've ever done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ooPd1XHTG6Wy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "s_qNSzzyaCbD"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}