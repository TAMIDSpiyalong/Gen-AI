{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAMIDSpiyalong/Gen-AI/blob/main/Lecture_3_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenE2varZEXc"
      },
      "source": [
        "# Transformers From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTSadDXiPQLm"
      },
      "source": [
        "This lab builds a sequence to sequence transformer, with encoder-decoder blocks from scratch for translation from Portuguese to English. Transformers excel at modeling sequential data, such as natural language. The datasets is from the TED Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAifCvd_Tth9"
      },
      "source": [
        "##Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg_2bsitTwAq"
      },
      "source": [
        "1. Understand and build the dot product self attention block, which is the key of the attention mechanism.\n",
        "2. Build a transformer from scratch with multiple attention heads.\n",
        "3. Train and evaluate the performance of such neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjJJyJTZYebt",
        "outputId": "7b86358f-ab58-435f-f404-6e411b049211"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-07 00:05:43.953442: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-07 00:05:51.524041: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-04-07 00:05:51.526840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-04-07 00:05:52.417880: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-07 00:05:54.305442: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-07 00:06:27.912625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsUXCHTln_F6",
        "outputId": "58ca7602-95f0-4a35-8b8d-c1d2261c399f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/scratch/user/piyalong/myclass/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow_datasets in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (4.9.8)\n",
            "Requirement already satisfied: absl-py in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (2.2.2)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (0.7.1)\n",
            "Requirement already satisfied: dm-tree in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.6.0 in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (1.26.1)\n",
            "Requirement already satisfied: promise in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (4.21.12)\n",
            "Requirement already satisfied: psutil in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.0)\n",
            "Requirement already satisfied: pyarrow in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (19.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (2.32.3)\n",
            "Requirement already satisfied: simple_parsing in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (1.17.0)\n",
            "Requirement already satisfied: termcolor in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (3.0.1)\n",
            "Requirement already satisfied: toml in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: typing_extensions in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (4.13.1)\n",
            "Requirement already satisfied: fsspec in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (2022.3.0)\n",
            "Requirement already satisfied: importlib_resources in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (5.7.1)\n",
            "Requirement already satisfied: zipp in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (3.8.0)\n",
            "Requirement already satisfied: einops in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (0.8.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from dm-tree->tensorflow_datasets) (25.3.0)\n",
            "Requirement already satisfied: six in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /scratch/user/piyalong/myclass/lib/python3.10/site-packages (from simple_parsing->tensorflow_datasets) (0.16)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/scratch/user/piyalong/myclass/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/scratch/user/piyalong/myclass/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_Qt8W1hJE_"
      },
      "source": [
        "Use [TFDS](https://www.tensorflow.org/datasets) to load the [Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt) from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate).\n",
        "\n",
        "This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "ed84df1b92734eff99552a7177beb74d",
            "77bdeddbbb55465a880edf647359ffa2",
            "108c9b656e1b4fdc8a124583a014ee07",
            "3f4a7e4e473847018569e8eef8d9079c",
            "83538dc956584f80aab0a3553a4c2e20",
            "acfea5cf86aa46d586ef467aed367852",
            "ecf8222ffd7d44108bbdd7a889d17ed8",
            "d46f57f212514ecb8799484386bcbbb9",
            "db5b4a418695476a995f946352c47b8f",
            "ec9cce86572a40b0824180560fbd328c",
            "ed9dbbe82c5f4f1f8fc1d7d37c98ac76",
            "92c751bb804e4cba994178651320ba06",
            "b83278e827284469a558ae21d640d58f",
            "288ca694d7ec4d368d5980c77479ec95",
            "13c9bda48f2f49d791f30ac609cf03c0",
            "7d1dca2c916445399cd938826395f540",
            "56d273f78fec4ae2b22c76c60dc8b84b",
            "f7ea139ae8b6464cb769ad4a7a017da8",
            "d5eefc26da004256bccf6fdbca2d22cf",
            "a9a81d00ea274b3c964e6c7d1d654c1e",
            "e245b92d898647c3a37dc4c447f58c4e",
            "965f7121fcd746df9d31d388527207e3",
            "db1f291ee9274686b01e50c936bff8a1",
            "59d2f93c2d3a4c5f849723ecb80d5ae7",
            "10d017039f8f45a983e8ac0f9109739b",
            "1c2451fc56624902a0b8b9463d72b197",
            "53e5a8d9944f4f269d4a95d423129b36",
            "389f91b83a8d41d88685749432ce5736",
            "63dbeb2d2ad04c079d00a880c0eb156d",
            "bc424264f61a426dba389e37b8b11f44",
            "286784f5cc934cacbcd5ce5f6be3930f",
            "bfd397bb1f6b454da7dd6f04a96c009b",
            "505aa9dee0d447aca04fdbfedf7f8193",
            "35181518a86741ef8a6ee7f3155bf3e9",
            "07e5fa3c48714ca5b5711246213cd292",
            "ec0f376cf5254a44a7c8925ec634e366",
            "4103ad9a36e446a2ab080f87a116a3dc",
            "b8c08feb51f444c4b36725e41c8b6b1a",
            "fcbe63a5186a4f648b4c78fb418de672",
            "5ca9daea6ef54245acc7a65a3d9dbfd5",
            "3d41d0fba7d54135bfb083b025ec0bff",
            "ad34eb4165e94733ba74bbb676d93e2d",
            "87835ca4d0834d32a263db7534d3cc09",
            "5247db5a1d0d4087b8adeaa94704b40d",
            "c645fa5423fa44ea81a42f1e3a10eddd",
            "04e17486f9bd4d81852ca2e625c29825",
            "6602c1266b234e379d2e399adf45936e",
            "fc88b86c0c324a5893beadc0f50e3310",
            "1812b061c3af41cd9f71bfd95d1dde2d",
            "5f48961a2e1b4b218729423c12ab4e33",
            "bff0f385e428498ebdb472818adac09a",
            "e728dabc548c458589e4b7aff0707070",
            "d852269a7234407fbbd6f46e08703c0c",
            "549df91bc0894142b33e7d2c9e102c6c",
            "172cb69fd62743b5881afc30b6bed07a",
            "e1171331da94407c88cce3b7f92ee89d",
            "eb51435aba5d4aa88351205f6b305e3d",
            "0010edb649504ae4ba18e51e249de5b9",
            "5d7a87a87da84e82911c647e2c493bf3",
            "67b4bf621b7a41cc81029d64bd736a01",
            "bbd1378c90204af0856b8d9e525d9713",
            "0397a1220c5a479f9b58fce48878f8d0",
            "72c0beeb2f334111a220f49196c8224b",
            "1523287f79574303a371aa11ff1b94d5",
            "17f388fa94a842a3b64dbcd58a0be33b",
            "f514f9d2da0d4b0db0e952979e6ece8c",
            "a648c82dc7a74deca087467b8e133428",
            "106478c43b5749acb1b48e0693106591",
            "1fe22484d262471eb844eb70acd8a73f",
            "5704f1efa9f44590b7df50d184aacdd6",
            "9644d7053a044b80818c665f3ee7a908",
            "50b0e1aed62f4e89826b680e67dc25b6",
            "f9ec63a0f08f4648858bdd674daf189d",
            "94f87a41debe46b390aafa85a9de2ffc",
            "2e3dfcd580f84d6189f1a3926030a3f7",
            "39aaec783b3d475eb0ce5863672e6d5c",
            "f36f7076baeb44168f5967bb9dae184b",
            "4a5a7695b7b84307bdd854964f723778",
            "92c10bf3fcb04addbfe123464bc6ca87",
            "ad84ea75e01a4af8b3c4c27509d454e1",
            "998002aebbb04b2fb0be4a09646f90d2",
            "b9514569fd8341e79501af1765f065e2",
            "6af756d29c7444baab1c645e35c3d4cd",
            "824cb88a5f1743fcadd5ceeaa1278ed8",
            "0ed9a4cc69a04fbfa9c596d8583dbfb8",
            "eb7b08905f8a4c109480a6a2c492ae2f",
            "831ad42bae9a41fd9efcbb08364a5582",
            "0d076caccf5e4d90b53956cb8cabb188",
            "659f7a722f1d4983a3b3aa3ae7bce634",
            "d6b69a87436c4f94a9e8f41fb0476fa4",
            "9cfa960d73f04c008b4e5d1b21869f74",
            "2d92dc4f2e414fa18f58ee36dfc57e44",
            "4bb9728dfeb34aceb0066dd1c9c332ae",
            "cf9ad00df0034a4f90f0abd527d38731",
            "6300fa2844d94b23b7530ce179727c95",
            "5aa7932fc45749388115068fda85a2cf",
            "fec64547ee6148ffb238dce03a7cfed6",
            "b32e596a6d3340d99fa35d3bc5c8092a",
            "1d8dcde09c7640fa800a075998138394",
            "bb20275d06944d3fade6033685f61bac",
            "f7a0197719ba44e8889aa3a2403cfc64",
            "6226d2feb0f949f3a9c65119487a3cf6",
            "5c36c4c4cf2841cdb16b6d10fc162e85",
            "3ca11c00f3a349a8a3e3bff1c9c96f5d",
            "a5b55e0824dd40d682f97bcafddd3afc",
            "afb2b0c0d21b4152a3a40e868d18e8cd",
            "79f082e92bdd4e0ba21958895c8c41ee",
            "0a5d26bcbcf44362852f55f678797ee2",
            "7feb8fe8b84947118052e5e756fdc9f1",
            "e4ba11abda60450980c1d5567d8d568d"
          ]
        },
        "id": "8q9t4FmN96eN",
        "outputId": "49867acd-7c97-4fc9-d2ac-99200bad070b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-07 00:09:13.562696: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
        "                               as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyTo86x5n1om",
        "outputId": "225474b0-788d-48e6-f446-972f74921bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Examples in Portuguese:\n",
            "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
            "mas e se estes fatores fossem ativos ?\n",
            "mas eles não tinham a curiosidade de me testar .\n",
            "\n",
            "> Examples in English:\n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
            "but what if it were active ?\n",
            "but they did n't test for curiosity .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-07 00:09:16.729193: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples in Portuguese:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Examples in English:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOe2oYkJE3ut"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCEKotqosGfq"
      },
      "source": [
        "Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a [token](https://developers.google.com/machine-learning/glossary#token) or token ID (a numeric representation).\n",
        "\n",
        "Tokenization is the process of breaking up text, into \"tokens\". Depending on the tokenizer, these tokens can represent sentence-pieces, words, subwords, or characters. To learn more about tokenization, visit [this guide](https://www.tensorflow.org/text/guide/tokenizers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVBg5Q8tBk5z"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DYWukNFkGQN",
        "outputId": "e4c7d5b4-bd9b-47db-b1d2-e9f74cff29af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
            "The original string: Transformer is awesome.\n"
          ]
        }
      ],
      "source": [
        "sample_string = 'Transformer is awesome.'\n",
        "\n",
        "tokenized_string = tokenizer_en.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_en.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9KJWJjrsZ4Y"
      },
      "source": [
        "The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2ntBxjkqK6",
        "outputId": "00bbd65a-bb82-46a2-8f26-6553d6e56992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|7915| ----> |T|\n",
            "|1248| ----> |ran|\n",
            "|7946| ----> |s|\n",
            "|7194| ----> |former |\n",
            "|13| ----> |is |\n",
            "|2799| ----> |awesome|\n",
            "|7877| ----> |.|\n"
          ]
        }
      ],
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('|{}| ----> |{}|'.format(ts, tokenizer_en.decode([ts])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FESLncJLFx-e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGi4PoVakxdc"
      },
      "source": [
        "Add a start and end token to the input and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZwnPr4R055s"
      },
      "outputs": [],
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
        "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "\n",
        "  return lang1, lang2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx1sFbR-9fRs"
      },
      "source": [
        "You want to use `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
        "\n",
        "* Graph tensors do not have a value.\n",
        "* In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mah1cS-P70Iz"
      },
      "outputs": [],
      "source": [
        "def tf_encode(pt, en):\n",
        "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
        "  result_pt.set_shape([None])\n",
        "  result_en.set_shape([None])\n",
        "\n",
        "  return result_pt, result_en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrGp5Gek6Ql"
      },
      "source": [
        "Note: To keep this example small and relatively fast, drop examples with a length of over 20 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QEgbjntk6Yf"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c081xPGv1CPI"
      },
      "outputs": [],
      "source": [
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mk9AZdZ5bcS"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_examples.map(tf_encode)\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_dataset = val_examples.map(tf_encode)\n",
        "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fXvfYVfQr2n",
        "outputId": "6626a34e-f971-4fd1-fe6a-d835bddbb360"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-07 00:11:21.330271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 38), dtype=int64, numpy=\n",
              " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
              "        [8214,   95,  198, ...,    0,    0,    0],\n",
              "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [8214, 1417, 8003, ...,    0,    0,    0],\n",
              "        [8214,   35, 1017, ...,    0,    0,    0],\n",
              "        [8214,  136, 3783, ...,    0,    0,    0]])>,\n",
              " TensorShape([32, 40]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pt_batch, en_batch = next(iter(val_dataset))\n",
        "pt_batch, en_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDkTVv3KMJX_"
      },
      "source": [
        "We'll start with the **Multi-Head Self-Attention** layer since that's the most involved bit. Once we have that working, the rest should make sense as you go."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqX04fFXBdxy"
      },
      "source": [
        "## Multi-Head Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NAf9HP7RsQu"
      },
      "source": [
        "\n",
        "Inside each attention head is a **Scaled Dot Product Self-Attention** operation as we covered in the slides. Given *queries*, *keys*, and *values*, the operation returns a new \"mix\" of the values.\n",
        "\n",
        "$$Attention(Q, K, V) = softmax(\\frac{QK^T)}{\\sqrt{d_k}})V$$\n",
        "\n",
        "The following function implements this and also takes a mask to account for padding and for masking future tokens for decoding (i.e. **look-ahead mask**). We'll cover masking later in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hpO6cGEN7HK"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_HhsreXh3H"
      },
      "source": [
        "Suppose our *queries*, *keys*, and *values* are each a length of 3 with a dimension of 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB2cDybgX5LZ",
        "outputId": "e816aefc-f260-4fe5-d873-9c25db635159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Queries:\n",
            " [[0.54668975 0.3798032  0.66348183 0.17317587]\n",
            " [0.32151094 0.9141733  0.79934067 0.09080518]\n",
            " [0.15384768 0.6878508  0.80139804 0.6002229 ]]\n"
          ]
        }
      ],
      "source": [
        "seq_len = 3\n",
        "embed_dim = 4\n",
        "\n",
        "queries = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "keys = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "values = np.random.rand(seq_len, embed_dim).astype('float32')\n",
        "\n",
        "print(\"Queries:\\n\", queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuNdMuz5vb1c"
      },
      "source": [
        "This would be the self-attention output and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxKj56hNX5UO",
        "outputId": "7962dc6c-c415-4169-9112-9b456535ca94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output\n",
            " tf.Tensor(\n",
            "[[0.73934394 0.41376865 0.6517496  0.23895578]\n",
            " [0.7340363  0.4121961  0.63228977 0.23050655]\n",
            " [0.72996396 0.40194172 0.6048719  0.22665203]], shape=(3, 4), dtype=float32) \n",
            "\n",
            "Weights\n",
            " tf.Tensor(\n",
            "[[0.32281268 0.30958366 0.36760366]\n",
            " [0.3507581  0.29791677 0.35132512]\n",
            " [0.38653967 0.29450783 0.31895244]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "output, attn_weights = scaled_dot_product_attention(queries, keys, values)\n",
        "\n",
        "print(\"Output\\n\", output, \"\\n\")\n",
        "print(\"Weights\\n\", attn_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72DBX3F5X1UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "5oS1aQOJky-3",
        "outputId": "07ea499c-4de5-46ea-d601-a7e82d60f408"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def visualize_attention(attention_weights):\n",
        "    # Create heatmap using seaborn\n",
        "    sns.set(font_scale=1.2)\n",
        "    plt.figure()\n",
        "    ax = sns.heatmap(\n",
        "        attention_weights,\n",
        "        cmap=\"YlGnBu\",\n",
        "        linewidths=0.5,\n",
        "        annot=True,\n",
        "        xticklabels=True,\n",
        "        yticklabels=True,\n",
        "        cbar_kws={'label': 'Attention Weight'}\n",
        "    )\n",
        "    ax.set_title('Self-Attention Weights')\n",
        "    plt.xlabel('Input Tokens')\n",
        "    plt.ylabel('Output Tokens')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_attention(attn_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBm9jbpSN6-L"
      },
      "source": [
        "Now that we have a way to calculate self-attention, let's actually generate the input *queries*, *keys*, and *values* for multiple heads. It's easier to understand things this way and we can certainly code it this way as well. But we can also \"simulate\" different heads with a single query matrix, single key matrix, and single value matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJLyGtqbX3uW",
        "outputId": "23ad544f-5a2f-40d9-d7c1-987c8038f7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of each head: 4\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "embed_dim = 12\n",
        "num_heads = 3\n",
        "head_dim = embed_dim // num_heads\n",
        "\n",
        "print(f\"Dimension of each head: {head_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDl37YzAf7bh"
      },
      "source": [
        "**Using separate weight matrices per head**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ_KoJq3fv-A"
      },
      "source": [
        "Suppose these are our input embeddings. Here we have a batch of 1 containing a sequence of length 3, with each element being a 12-dimensional embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NcX3KBrX3uW",
        "outputId": "b6815239-2c5d-4735-c096-cc5d63a80238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape:  (1, 3, 12) \n",
            "\n",
            "Input:\n",
            " [[[0.9 0.5 0.6 0.4 0.  0.8 0.5 0.2 0.1 0.9 0.9 0.1]\n",
            "  [0.7 0.4 0.2 0.2 0.4 0.8 0.9 0.8 0.8 0.4 0.5 0.5]\n",
            "  [0.7 0.5 0.9 0.5 0.5 0.8 0.2 0.2 0.3 0.4 1.  0.8]]]\n"
          ]
        }
      ],
      "source": [
        "x = np.random.rand(batch_size, seq_len, embed_dim).round(1).astype('float32')\n",
        "print(\"Input shape: \", x.shape, \"\\n\")\n",
        "print(\"Input:\\n\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvJicbp6f7pI"
      },
      "source": [
        "We'll declare three sets of *query* weights (one for each head), three sets of *key* weights, and three sets of *value* weights. Remember each weight matrix should have a dimension of $\\text{d}\\ \\text{x}\\ \\text{d/h}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zdg7rqrX3uX"
      },
      "outputs": [],
      "source": [
        "# The query weights for each head.\n",
        "wq0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wq1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wq2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "\n",
        "# The key weights for each head.\n",
        "wk0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wk1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wk2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "\n",
        "# The value weights for each head.\n",
        "wv0 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wv1 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')\n",
        "wv2 = np.random.rand(embed_dim, head_dim).round(1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMRHZooX3uX",
        "outputId": "f0de9afd-b4d7-4efb-be09-59cd0e20a6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The three sets of query weights (one for each head):\n",
            "wq0:\n",
            " [[0.8 0.6 0.9 0.5]\n",
            " [0.7 0.3 0.1 0.5]\n",
            " [0.1 0.  0.8 0.3]\n",
            " [0.5 0.9 0.  0.8]\n",
            " [0.1 0.5 0.7 0.1]\n",
            " [0.2 0.9 0.4 0.7]\n",
            " [0.9 0.4 0.7 0.2]\n",
            " [0.8 0.7 0.5 0.1]\n",
            " [0.7 0.9 0.4 0.7]\n",
            " [0.5 0.2 0.1 0.9]\n",
            " [1.  0.5 0.8 0.8]\n",
            " [0.7 0.9 0.6 0.2]]\n",
            "wq1:\n",
            " [[0.5 0.3 0.4 0.9]\n",
            " [0.5 0.6 0.4 0. ]\n",
            " [0.6 0.8 0.1 0.7]\n",
            " [0.7 0.5 0.5 0.5]\n",
            " [0.2 0.3 0.6 0.9]\n",
            " [0.4 0.3 0.2 0.7]\n",
            " [0.1 0.1 0.6 0.9]\n",
            " [0.1 1.  0.9 0.8]\n",
            " [0.9 0.6 0.6 0.1]\n",
            " [0.1 0.5 0.9 0. ]\n",
            " [0.2 0.9 0.7 0.3]\n",
            " [0.7 0.4 0.1 0.8]]\n",
            "wq2:\n",
            " [[0.5 0.3 0.4 0.9]\n",
            " [0.5 0.6 0.4 0. ]\n",
            " [0.6 0.8 0.1 0.7]\n",
            " [0.7 0.5 0.5 0.5]\n",
            " [0.2 0.3 0.6 0.9]\n",
            " [0.4 0.3 0.2 0.7]\n",
            " [0.1 0.1 0.6 0.9]\n",
            " [0.1 1.  0.9 0.8]\n",
            " [0.9 0.6 0.6 0.1]\n",
            " [0.1 0.5 0.9 0. ]\n",
            " [0.2 0.9 0.7 0.3]\n",
            " [0.7 0.4 0.1 0.8]]\n"
          ]
        }
      ],
      "source": [
        "print(\"The three sets of query weights (one for each head):\")\n",
        "print(\"wq0:\\n\", wq0)\n",
        "print(\"wq1:\\n\", wq1)\n",
        "print(\"wq2:\\n\", wq1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmwGKV9qgch-"
      },
      "source": [
        "We'll generate our *queries*, *keys*, and *values* for each head by multiplying our input by the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NucbYNNSX3uX"
      },
      "outputs": [],
      "source": [
        "# Geneated queries, keys, and values for the first head.\n",
        "q0 = np.dot(x, wq0)\n",
        "k0 = np.dot(x, wk0)\n",
        "v0 = np.dot(x, wv0)\n",
        "\n",
        "# Geneated queries, keys, and values for the second head.\n",
        "q1 = np.dot(x, wq1)\n",
        "k1 = np.dot(x, wk1)\n",
        "v1 = np.dot(x, wv1)\n",
        "\n",
        "# Geneated queries, keys, and values for the third head.\n",
        "q2 = np.dot(x, wq2)\n",
        "k2 = np.dot(x, wk2)\n",
        "v2 = np.dot(x, wv2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIDiwWZ0gqhm"
      },
      "source": [
        "These are the resulting *query*, *key*, and *value* vectors for the first head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMcMmbkqX3uX",
        "outputId": "bc166bc0-ce3b-43c7-d83f-ec256474a8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q, K, and V for first head:\n",
            "\n",
            "q0 (1, 3, 4):\n",
            " [[[3.59      2.9199998 3.02      3.5      ]\n",
            "  [4.2200003 4.06      3.52      3.05     ]\n",
            "  [3.77      3.78      3.75      3.47     ]]] \n",
            "\n",
            "k0 (1, 3, 4):\n",
            " [[[2.63      2.8600001 2.82      3.54     ]\n",
            "  [3.33      3.1000001 3.5700002 3.55     ]\n",
            "  [3.46      3.66      3.98      3.9099998]]] \n",
            "\n",
            "v0 (1, 3, 4):\n",
            " [[[3.33      4.02      2.23      2.87     ]\n",
            "  [3.55      3.8200002 3.47      3.75     ]\n",
            "  [4.12      4.16      2.43      3.37     ]]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Q, K, and V for first head:\\n\")\n",
        "\n",
        "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
        "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
        "print(f\"v0 {v0.shape}:\\n\", v0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw5CQ9i6qZDv"
      },
      "source": [
        "Now that we have our Q, K, V vectors, we can just pass them to our self-attention operation. Here we're calculating the output and attention weights for the first head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7tHIvXKX3uX",
        "outputId": "a23e9cc6-e991-4fa9-c892-756674ab540c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from first attention head:  tf.Tensor(\n",
            "[[[4.0638175 4.1283927 2.5230684 3.4015503]\n",
            "  [4.0817075 4.13794   2.4959955 3.3931067]\n",
            "  [4.0820546 4.1382194 2.4950047 3.3926516]]], shape=(1, 3, 4), dtype=float32) \n",
            "\n",
            "Attention weights from first head:  tf.Tensor(\n",
            "[[[0.0057517  0.09059467 0.9036537 ]\n",
            "  [0.00235853 0.06391079 0.93373066]\n",
            "  [0.00257649 0.06299969 0.93442386]]], shape=(1, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "out0, attn_weights0 = scaled_dot_product_attention(q0, k0, v0)\n",
        "\n",
        "print(\"Output from first attention head: \", out0, \"\\n\")\n",
        "print(\"Attention weights from first head: \", attn_weights0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoYEXSm7qr_A"
      },
      "source": [
        "Here are the other two (attention weights are ignored)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otnqbaDSqpJ7",
        "outputId": "45ae93e5-5950-4528-abc0-e6cdccc92090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from second attention head:  tf.Tensor(\n",
            "[[[4.0636554 3.3040717 3.314179  3.502932 ]\n",
            "  [4.086827  3.309157  3.3262255 3.5121942]\n",
            "  [4.121911  3.3194544 3.351761  3.533568 ]]], shape=(1, 3, 4), dtype=float32) \n",
            "\n",
            "Output from third attention head:  tf.Tensor(\n",
            "[[[2.7901866 2.8710148 3.5612853 3.5424993]\n",
            "  [2.7441692 2.8970602 3.533613  3.541515 ]\n",
            "  [2.7799892 2.8777633 3.5570111 3.5437198]]], shape=(1, 3, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "out1, _ = scaled_dot_product_attention(q1, k1, v1)\n",
        "out2, _ = scaled_dot_product_attention(q2, k2, v2)\n",
        "\n",
        "print(\"Output from second attention head: \", out1, \"\\n\")\n",
        "print(\"Output from third attention head: \", out2,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOV717bqX3uX"
      },
      "source": [
        "As we covered in the slides, once we have each head's output, we concatenate them and then put them through a linear layer for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmSv5trtt2v9",
        "outputId": "45db4201-73da-43c6-bcf0-57da77dc7d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined output from all heads (1, 3, 12):\n",
            "[[[4.0638175 4.1283927 2.5230684 3.4015503 4.0636554 3.3040717 3.314179\n",
            "   3.502932  2.7901866 2.8710148 3.5612853 3.5424993]\n",
            "  [4.0817075 4.13794   2.4959955 3.3931067 4.086827  3.309157  3.3262255\n",
            "   3.5121942 2.7441692 2.8970602 3.533613  3.541515 ]\n",
            "  [4.0820546 4.1382194 2.4950047 3.3926516 4.121911  3.3194544 3.351761\n",
            "   3.533568  2.7799892 2.8777633 3.5570111 3.5437198]]]\n"
          ]
        }
      ],
      "source": [
        "combined_out_a = np.concatenate((out0, out1, out2), axis=-1)\n",
        "print(f\"Combined output from all heads {combined_out_a.shape}:\")\n",
        "print(combined_out_a)\n",
        "\n",
        "# The final step would be to run combined_out_a through a linear/dense layer\n",
        "# for further processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.\n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSV3PPKsYecw"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu94p-_-2_BX",
        "outputId": "726730d2-03ec-4f32-f0cc-828bdeb3d3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([2, 3, 4]), TensorShape([2, 2, 3, 3]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_mha = MultiHeadAttention(d_model=4, num_heads=2)\n",
        "y = tf.random.uniform((2, 3, 4))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(v=y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCf03zinNsHA",
        "outputId": "76b0dd51-2560-4159-9ccb-37a252868037"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0.33975732, 0.33772483, 0.3225179 ],\n",
              "       [0.20027722, 0.59952796, 0.20019482],\n",
              "       [0.3342905 , 0.34223723, 0.32347226]], dtype=float32)>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attn[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.\n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhIOZjMNKujn"
      },
      "outputs": [],
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "1kLCla68EloE",
        "outputId": "bb687a50-6597-40e5-d513-800df1d679f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 10, 512)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pos_encoding = positional_encoding(10, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2i8-e1s8ti9"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7BYeBCNvi7n",
        "outputId": "f6645eff-b035-49d2-a846-3fae1bda5c00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG5gqr1nXkPM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVxS8OPI9uI0"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxKGuXxaBeeE",
        "outputId": "f736571e-de8a-4433-f95d-a4d7277fc261"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.random.uniform((3, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET7xLt0yCT6Z"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mytb1lPyOHLB",
        "outputId": "0326b764-853f-4586-caa1-dc6551d67a34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 3])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_ffn = point_wise_feed_forward_network(3, 4)\n",
        "sample_ffn(tf.random.uniform((64, 3, 4))).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF6fNkn7yzvJ",
        "outputId": "29f3e907-4690-4fbb-d517-b18b2fefd4b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (64, 3, 4)                20        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (64, 3, 3)                15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35 (140.00 Byte)\n",
            "Trainable params: 35 (140.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sample_ffn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask)\n",
        "2.    Point wise feed forward networks.\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzZRXdO0mI48",
        "outputId": "3f8b075e-f021-442c-bea0-af8fc6f17c4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 4])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(4, 2, 7)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 3, 4)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne2Bqx8k71l0",
        "outputId": "9118e523-2965-4e70-e3c8-875d81069856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 4])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(4, 2, 7)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 3, 4)), sample_encoder_layer_output,\n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnquLx56zZdk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPIHBjvsCPYW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QG9nueFQKXx",
        "outputId": "1f928599-99a1-4371-d7f3-4ba41b58821c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(512, 3, 4)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder = Encoder(num_layers=1, d_model=4, num_heads=2,\n",
        "                         dff=7, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLwqNG9_zYy9",
        "outputId": "79f8e84f-4d37-401c-8d43-585a77895251"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.02154297,  0.00951443,  0.02964132, -0.00389347], dtype=float32)>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eb=tf.keras.layers.Embedding(800, 4)\n",
        "eb(622)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na3WMc6-7n-G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1jXoAMRZyvu",
        "outputId": "b82f0595-f6f9-4c40-f5a5-a3cd4952cb26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([64, 3, 4]), TensorShape([64, 2, 3, 24]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=4, num_heads=2,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEnC2EYpzzvc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ4fbQcIkHW1",
        "outputId": "0141ff0d-6547-4c92-da63-ba0844168e7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([512, 3, 8000])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=4, num_heads=2, dff=7,\n",
        "    input_vocab_size=8500, target_vocab_size=8000,\n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((512, 3), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzF0uyBTzhOG",
        "outputId": "d6b3f321-83b4-4b2d-eaf3-ef3af5603673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  34326     \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  32502     \n",
            "                                                                 \n",
            " dense_80 (Dense)            multiple                  40000     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 106828 (417.30 KB)\n",
            "Trainable params: 106828 (417.30 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sample_transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP5fk79FzgN5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced.\n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnJn5SLA2ahP"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a_CTrcQzJ6U"
      },
      "outputs": [],
      "source": [
        "decay_steps = 10\n",
        "initial_learning_rate = 0.001\n",
        "warmup_steps = 10\n",
        "target_learning_rate = 0.0004\n",
        "lr_warmup_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate, decay_steps, warmup_target=target_learning_rate,\n",
        "    warmup_steps=warmup_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwESUUznx0Ke",
        "outputId": "f4500088-cc31-44aa-9663-af0950e7bc07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.optimizers.schedules.learning_rate_schedule.CosineDecay at 0x14da13077370>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_warmup_decayed_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlhsJMm0TW_B"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67oqVHiT0Eiu"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phlyxMnm-Tpx"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOJUSB1T8GjM"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNhuYfllndLZ",
        "outputId": "bd988972-ca6c-4477-c390-595f33c7f9fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
        "\n",
        "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
        "\n",
        "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
        "\n",
        "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKpoA6q1sJFj"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJwmp9OE29oj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "Portuguese is used as the input language and English is the target language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbvmaKNiznHZ",
        "outputId": "3ab260b9-9ea3-4533-d707-455d67d36fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.5607 Accuracy 0.2062\n",
            "Epoch 1 Batch 50 Loss 3.5194 Accuracy 0.2119\n",
            "Epoch 1 Batch 100 Loss 3.5209 Accuracy 0.2124\n",
            "Epoch 1 Batch 150 Loss 3.5120 Accuracy 0.2150\n",
            "Epoch 1 Batch 200 Loss 3.5076 Accuracy 0.2161\n",
            "Epoch 1 Batch 250 Loss 3.5032 Accuracy 0.2167\n",
            "Epoch 1 Batch 300 Loss 3.5007 Accuracy 0.2159\n",
            "Epoch 1 Batch 350 Loss 3.5029 Accuracy 0.2150\n",
            "Epoch 1 Batch 400 Loss 3.5027 Accuracy 0.2148\n",
            "Epoch 1 Batch 450 Loss 3.5030 Accuracy 0.2153\n",
            "Epoch 1 Batch 500 Loss 3.5038 Accuracy 0.2153\n",
            "Epoch 1 Batch 550 Loss 3.4998 Accuracy 0.2160\n",
            "Epoch 1 Batch 600 Loss 3.5027 Accuracy 0.2159\n",
            "Epoch 1 Batch 650 Loss 3.5024 Accuracy 0.2164\n",
            "Epoch 1 Batch 700 Loss 3.5011 Accuracy 0.2164\n",
            "Epoch 1 Batch 750 Loss 3.4995 Accuracy 0.2166\n",
            "Epoch 1 Batch 800 Loss 3.4961 Accuracy 0.2169\n",
            "Epoch 1 Batch 850 Loss 3.4946 Accuracy 0.2171\n",
            "Epoch 1 Batch 900 Loss 3.4947 Accuracy 0.2173\n",
            "Epoch 1 Batch 950 Loss 3.4972 Accuracy 0.2173\n",
            "Epoch 1 Batch 1000 Loss 3.4959 Accuracy 0.2178\n",
            "Epoch 1 Batch 1050 Loss 3.4946 Accuracy 0.2180\n",
            "Epoch 1 Batch 1100 Loss 3.4936 Accuracy 0.2182\n",
            "Epoch 1 Batch 1150 Loss 3.4952 Accuracy 0.2181\n",
            "Epoch 1 Batch 1200 Loss 3.4915 Accuracy 0.2184\n",
            "Epoch 1 Batch 1250 Loss 3.4901 Accuracy 0.2185\n",
            "Epoch 1 Batch 1300 Loss 3.4885 Accuracy 0.2184\n",
            "Epoch 1 Batch 1350 Loss 3.4877 Accuracy 0.2184\n",
            "Epoch 1 Batch 1400 Loss 3.4870 Accuracy 0.2185\n",
            "Epoch 1 Loss 3.4868 Accuracy 0.2185\n",
            "Time taken for 1 epoch: 1034.6408517360687 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 3.3630 Accuracy 0.2420\n",
            "Epoch 2 Batch 50 Loss 3.4142 Accuracy 0.2220\n",
            "Epoch 2 Batch 100 Loss 3.4016 Accuracy 0.2219\n",
            "Epoch 2 Batch 150 Loss 3.4002 Accuracy 0.2231\n",
            "Epoch 2 Batch 200 Loss 3.3994 Accuracy 0.2240\n",
            "Epoch 2 Batch 250 Loss 3.3956 Accuracy 0.2242\n",
            "Epoch 2 Batch 300 Loss 3.3865 Accuracy 0.2243\n",
            "Epoch 2 Batch 350 Loss 3.3883 Accuracy 0.2249\n",
            "Epoch 2 Batch 400 Loss 3.3886 Accuracy 0.2255\n",
            "Epoch 2 Batch 450 Loss 3.3866 Accuracy 0.2257\n",
            "Epoch 2 Batch 500 Loss 3.3851 Accuracy 0.2259\n",
            "Epoch 2 Batch 550 Loss 3.3869 Accuracy 0.2255\n",
            "Epoch 2 Batch 600 Loss 3.3870 Accuracy 0.2255\n",
            "Epoch 2 Batch 650 Loss 3.3865 Accuracy 0.2253\n",
            "Epoch 2 Batch 700 Loss 3.3853 Accuracy 0.2253\n",
            "Epoch 2 Batch 750 Loss 3.3872 Accuracy 0.2252\n",
            "Epoch 2 Batch 800 Loss 3.3871 Accuracy 0.2251\n",
            "Epoch 2 Batch 850 Loss 3.3864 Accuracy 0.2254\n",
            "Epoch 2 Batch 900 Loss 3.3832 Accuracy 0.2254\n",
            "Epoch 2 Batch 950 Loss 3.3816 Accuracy 0.2256\n",
            "Epoch 2 Batch 1000 Loss 3.3851 Accuracy 0.2255\n",
            "Epoch 2 Batch 1050 Loss 3.3850 Accuracy 0.2256\n",
            "Epoch 2 Batch 1100 Loss 3.3848 Accuracy 0.2255\n",
            "Epoch 2 Batch 1150 Loss 3.3829 Accuracy 0.2257\n",
            "Epoch 2 Batch 1200 Loss 3.3822 Accuracy 0.2257\n",
            "Epoch 2 Batch 1250 Loss 3.3808 Accuracy 0.2258\n",
            "Epoch 2 Batch 1300 Loss 3.3803 Accuracy 0.2257\n",
            "Epoch 2 Batch 1350 Loss 3.3798 Accuracy 0.2257\n",
            "Epoch 2 Batch 1400 Loss 3.3783 Accuracy 0.2257\n",
            "Epoch 2 Loss 3.3785 Accuracy 0.2257\n",
            "Time taken for 1 epoch: 1023.2316663265228 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 3.4390 Accuracy 0.2089\n",
            "Epoch 3 Batch 50 Loss 3.3013 Accuracy 0.2286\n",
            "Epoch 3 Batch 100 Loss 3.3154 Accuracy 0.2285\n",
            "Epoch 3 Batch 150 Loss 3.3060 Accuracy 0.2292\n",
            "Epoch 3 Batch 200 Loss 3.3098 Accuracy 0.2307\n",
            "Epoch 3 Batch 250 Loss 3.2986 Accuracy 0.2300\n",
            "Epoch 3 Batch 300 Loss 3.3016 Accuracy 0.2302\n",
            "Epoch 3 Batch 350 Loss 3.2979 Accuracy 0.2306\n",
            "Epoch 3 Batch 400 Loss 3.2971 Accuracy 0.2306\n",
            "Epoch 3 Batch 450 Loss 3.2918 Accuracy 0.2308\n",
            "Epoch 3 Batch 500 Loss 3.2916 Accuracy 0.2307\n",
            "Epoch 3 Batch 550 Loss 3.2942 Accuracy 0.2309\n",
            "Epoch 3 Batch 600 Loss 3.2945 Accuracy 0.2312\n",
            "Epoch 3 Batch 650 Loss 3.2919 Accuracy 0.2311\n",
            "Epoch 3 Batch 700 Loss 3.2894 Accuracy 0.2315\n",
            "Epoch 3 Batch 750 Loss 3.2883 Accuracy 0.2316\n",
            "Epoch 3 Batch 800 Loss 3.2849 Accuracy 0.2315\n",
            "Epoch 3 Batch 850 Loss 3.2821 Accuracy 0.2319\n",
            "Epoch 3 Batch 900 Loss 3.2824 Accuracy 0.2320\n",
            "Epoch 3 Batch 950 Loss 3.2818 Accuracy 0.2318\n",
            "Epoch 3 Batch 1000 Loss 3.2811 Accuracy 0.2318\n",
            "Epoch 3 Batch 1050 Loss 3.2808 Accuracy 0.2320\n",
            "Epoch 3 Batch 1100 Loss 3.2823 Accuracy 0.2318\n",
            "Epoch 3 Batch 1150 Loss 3.2809 Accuracy 0.2320\n",
            "Epoch 3 Batch 1200 Loss 3.2794 Accuracy 0.2323\n",
            "Epoch 3 Batch 1250 Loss 3.2786 Accuracy 0.2322\n",
            "Epoch 3 Batch 1300 Loss 3.2782 Accuracy 0.2323\n",
            "Epoch 3 Batch 1350 Loss 3.2774 Accuracy 0.2323\n",
            "Epoch 3 Batch 1400 Loss 3.2767 Accuracy 0.2324\n",
            "Epoch 3 Loss 3.2768 Accuracy 0.2323\n",
            "Time taken for 1 epoch: 1007.0180580615997 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 3.3160 Accuracy 0.2510\n",
            "Epoch 4 Batch 50 Loss 3.2202 Accuracy 0.2365\n",
            "Epoch 4 Batch 100 Loss 3.2074 Accuracy 0.2357\n",
            "Epoch 4 Batch 150 Loss 3.1987 Accuracy 0.2365\n",
            "Epoch 4 Batch 200 Loss 3.1918 Accuracy 0.2374\n",
            "Epoch 4 Batch 250 Loss 3.1870 Accuracy 0.2369\n",
            "Epoch 4 Batch 300 Loss 3.1885 Accuracy 0.2370\n",
            "Epoch 4 Batch 350 Loss 3.1893 Accuracy 0.2372\n",
            "Epoch 4 Batch 400 Loss 3.1878 Accuracy 0.2368\n",
            "Epoch 4 Batch 450 Loss 3.1933 Accuracy 0.2368\n",
            "Epoch 4 Batch 500 Loss 3.1940 Accuracy 0.2366\n",
            "Epoch 4 Batch 550 Loss 3.1928 Accuracy 0.2369\n",
            "Epoch 4 Batch 600 Loss 3.1940 Accuracy 0.2369\n",
            "Epoch 4 Batch 650 Loss 3.1907 Accuracy 0.2369\n",
            "Epoch 4 Batch 700 Loss 3.1931 Accuracy 0.2370\n",
            "Epoch 4 Batch 750 Loss 3.1916 Accuracy 0.2369\n",
            "Epoch 4 Batch 800 Loss 3.1900 Accuracy 0.2370\n",
            "Epoch 4 Batch 850 Loss 3.1859 Accuracy 0.2373\n",
            "Epoch 4 Batch 900 Loss 3.1889 Accuracy 0.2373\n",
            "Epoch 4 Batch 950 Loss 3.1891 Accuracy 0.2374\n",
            "Epoch 4 Batch 1000 Loss 3.1897 Accuracy 0.2375\n",
            "Epoch 4 Batch 1050 Loss 3.1894 Accuracy 0.2374\n",
            "Epoch 4 Batch 1100 Loss 3.1872 Accuracy 0.2375\n",
            "Epoch 4 Batch 1150 Loss 3.1870 Accuracy 0.2374\n",
            "Epoch 4 Batch 1200 Loss 3.1869 Accuracy 0.2373\n",
            "Epoch 4 Batch 1250 Loss 3.1859 Accuracy 0.2373\n",
            "Epoch 4 Batch 1300 Loss 3.1847 Accuracy 0.2372\n",
            "Epoch 4 Batch 1350 Loss 3.1854 Accuracy 0.2373\n",
            "Epoch 4 Batch 1400 Loss 3.1836 Accuracy 0.2374\n",
            "Epoch 4 Loss 3.1833 Accuracy 0.2375\n",
            "Time taken for 1 epoch: 1006.5272867679596 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.6979 Accuracy 0.2230\n",
            "Epoch 5 Batch 50 Loss 3.1114 Accuracy 0.2389\n",
            "Epoch 5 Batch 100 Loss 3.1199 Accuracy 0.2429\n",
            "Epoch 5 Batch 150 Loss 3.1067 Accuracy 0.2437\n",
            "Epoch 5 Batch 200 Loss 3.1142 Accuracy 0.2426\n",
            "Epoch 5 Batch 250 Loss 3.1074 Accuracy 0.2433\n",
            "Epoch 5 Batch 300 Loss 3.1084 Accuracy 0.2428\n",
            "Epoch 5 Batch 350 Loss 3.1046 Accuracy 0.2427\n",
            "Epoch 5 Batch 400 Loss 3.1016 Accuracy 0.2424\n",
            "Epoch 5 Batch 450 Loss 3.1019 Accuracy 0.2424\n",
            "Epoch 5 Batch 500 Loss 3.1027 Accuracy 0.2428\n",
            "Epoch 5 Batch 550 Loss 3.1007 Accuracy 0.2429\n",
            "Epoch 5 Batch 600 Loss 3.0989 Accuracy 0.2431\n",
            "Epoch 5 Batch 650 Loss 3.0974 Accuracy 0.2429\n",
            "Epoch 5 Batch 700 Loss 3.0951 Accuracy 0.2429\n",
            "Epoch 5 Batch 750 Loss 3.0952 Accuracy 0.2427\n",
            "Epoch 5 Batch 800 Loss 3.0938 Accuracy 0.2429\n",
            "Epoch 5 Batch 850 Loss 3.0935 Accuracy 0.2428\n",
            "Epoch 5 Batch 900 Loss 3.0940 Accuracy 0.2428\n",
            "Epoch 5 Batch 950 Loss 3.0934 Accuracy 0.2427\n",
            "Epoch 5 Batch 1000 Loss 3.0930 Accuracy 0.2427\n",
            "Epoch 5 Batch 1050 Loss 3.0919 Accuracy 0.2427\n",
            "Epoch 5 Batch 1100 Loss 3.0917 Accuracy 0.2428\n",
            "Epoch 5 Batch 1150 Loss 3.0932 Accuracy 0.2428\n",
            "Epoch 5 Batch 1200 Loss 3.0945 Accuracy 0.2428\n",
            "Epoch 5 Batch 1250 Loss 3.0942 Accuracy 0.2429\n",
            "Epoch 5 Batch 1300 Loss 3.0943 Accuracy 0.2429\n",
            "Epoch 5 Batch 1350 Loss 3.0933 Accuracy 0.2430\n",
            "Epoch 5 Batch 1400 Loss 3.0925 Accuracy 0.2430\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-3\n",
            "Epoch 5 Loss 3.0926 Accuracy 0.2430\n",
            "Time taken for 1 epoch: 999.5085306167603 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.9156 Accuracy 0.2679\n",
            "Epoch 6 Batch 50 Loss 3.0091 Accuracy 0.2462\n",
            "Epoch 6 Batch 100 Loss 2.9975 Accuracy 0.2466\n",
            "Epoch 6 Batch 150 Loss 3.0147 Accuracy 0.2454\n",
            "Epoch 6 Batch 200 Loss 3.0123 Accuracy 0.2469\n",
            "Epoch 6 Batch 250 Loss 3.0145 Accuracy 0.2473\n",
            "Epoch 6 Batch 300 Loss 3.0134 Accuracy 0.2469\n",
            "Epoch 6 Batch 350 Loss 3.0110 Accuracy 0.2468\n",
            "Epoch 6 Batch 400 Loss 3.0103 Accuracy 0.2468\n",
            "Epoch 6 Batch 450 Loss 3.0103 Accuracy 0.2467\n",
            "Epoch 6 Batch 500 Loss 3.0126 Accuracy 0.2469\n",
            "Epoch 6 Batch 550 Loss 3.0164 Accuracy 0.2472\n",
            "Epoch 6 Batch 600 Loss 3.0124 Accuracy 0.2476\n",
            "Epoch 6 Batch 650 Loss 3.0118 Accuracy 0.2477\n",
            "Epoch 6 Batch 700 Loss 3.0108 Accuracy 0.2479\n",
            "Epoch 6 Batch 750 Loss 3.0101 Accuracy 0.2481\n",
            "Epoch 6 Batch 800 Loss 3.0106 Accuracy 0.2482\n",
            "Epoch 6 Batch 850 Loss 3.0109 Accuracy 0.2482\n",
            "Epoch 6 Batch 900 Loss 3.0100 Accuracy 0.2483\n",
            "Epoch 6 Batch 950 Loss 3.0101 Accuracy 0.2481\n",
            "Epoch 6 Batch 1000 Loss 3.0105 Accuracy 0.2482\n",
            "Epoch 6 Batch 1050 Loss 3.0095 Accuracy 0.2483\n",
            "Epoch 6 Batch 1100 Loss 3.0071 Accuracy 0.2484\n",
            "Epoch 6 Batch 1150 Loss 3.0077 Accuracy 0.2483\n",
            "Epoch 6 Batch 1200 Loss 3.0066 Accuracy 0.2484\n",
            "Epoch 6 Batch 1250 Loss 3.0080 Accuracy 0.2482\n",
            "Epoch 6 Batch 1300 Loss 3.0085 Accuracy 0.2481\n",
            "Epoch 6 Batch 1350 Loss 3.0079 Accuracy 0.2482\n",
            "Epoch 6 Batch 1400 Loss 3.0095 Accuracy 0.2481\n",
            "Epoch 6 Loss 3.0091 Accuracy 0.2481\n",
            "Time taken for 1 epoch: 990.8112289905548 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 3.1684 Accuracy 0.2311\n",
            "Epoch 7 Batch 50 Loss 2.8906 Accuracy 0.2515\n",
            "Epoch 7 Batch 100 Loss 2.9103 Accuracy 0.2530\n",
            "Epoch 7 Batch 150 Loss 2.9213 Accuracy 0.2515\n",
            "Epoch 7 Batch 200 Loss 2.9262 Accuracy 0.2512\n",
            "Epoch 7 Batch 250 Loss 2.9354 Accuracy 0.2521\n",
            "Epoch 7 Batch 300 Loss 2.9293 Accuracy 0.2528\n",
            "Epoch 7 Batch 350 Loss 2.9319 Accuracy 0.2525\n",
            "Epoch 7 Batch 400 Loss 2.9348 Accuracy 0.2520\n",
            "Epoch 7 Batch 450 Loss 2.9308 Accuracy 0.2520\n",
            "Epoch 7 Batch 500 Loss 2.9282 Accuracy 0.2520\n",
            "Epoch 7 Batch 550 Loss 2.9280 Accuracy 0.2526\n",
            "Epoch 7 Batch 600 Loss 2.9286 Accuracy 0.2524\n",
            "Epoch 7 Batch 650 Loss 2.9268 Accuracy 0.2525\n",
            "Epoch 7 Batch 700 Loss 2.9280 Accuracy 0.2521\n",
            "Epoch 7 Batch 750 Loss 2.9283 Accuracy 0.2519\n",
            "Epoch 7 Batch 800 Loss 2.9309 Accuracy 0.2521\n",
            "Epoch 7 Batch 850 Loss 2.9293 Accuracy 0.2525\n",
            "Epoch 7 Batch 900 Loss 2.9276 Accuracy 0.2526\n",
            "Epoch 7 Batch 950 Loss 2.9252 Accuracy 0.2527\n",
            "Epoch 7 Batch 1000 Loss 2.9267 Accuracy 0.2526\n",
            "Epoch 7 Batch 1050 Loss 2.9267 Accuracy 0.2528\n",
            "Epoch 7 Batch 1100 Loss 2.9267 Accuracy 0.2526\n",
            "Epoch 7 Batch 1150 Loss 2.9255 Accuracy 0.2528\n",
            "Epoch 7 Batch 1200 Loss 2.9243 Accuracy 0.2528\n",
            "Epoch 7 Batch 1250 Loss 2.9251 Accuracy 0.2526\n",
            "Epoch 7 Batch 1300 Loss 2.9264 Accuracy 0.2527\n",
            "Epoch 7 Batch 1350 Loss 2.9261 Accuracy 0.2526\n",
            "Epoch 7 Batch 1400 Loss 2.9266 Accuracy 0.2528\n",
            "Epoch 7 Loss 2.9267 Accuracy 0.2528\n",
            "Time taken for 1 epoch: 987.2943999767303 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 3.0766 Accuracy 0.2524\n",
            "Epoch 8 Batch 50 Loss 2.8560 Accuracy 0.2575\n",
            "Epoch 8 Batch 100 Loss 2.8456 Accuracy 0.2568\n",
            "Epoch 8 Batch 150 Loss 2.8480 Accuracy 0.2571\n",
            "Epoch 8 Batch 200 Loss 2.8470 Accuracy 0.2581\n",
            "Epoch 8 Batch 250 Loss 2.8462 Accuracy 0.2576\n",
            "Epoch 8 Batch 300 Loss 2.8504 Accuracy 0.2569\n",
            "Epoch 8 Batch 350 Loss 2.8607 Accuracy 0.2558\n",
            "Epoch 8 Batch 400 Loss 2.8628 Accuracy 0.2562\n",
            "Epoch 8 Batch 450 Loss 2.8603 Accuracy 0.2564\n",
            "Epoch 8 Batch 500 Loss 2.8619 Accuracy 0.2561\n",
            "Epoch 8 Batch 550 Loss 2.8598 Accuracy 0.2563\n",
            "Epoch 8 Batch 600 Loss 2.8595 Accuracy 0.2561\n",
            "Epoch 8 Batch 650 Loss 2.8546 Accuracy 0.2564\n",
            "Epoch 8 Batch 700 Loss 2.8541 Accuracy 0.2565\n",
            "Epoch 8 Batch 750 Loss 2.8534 Accuracy 0.2564\n",
            "Epoch 8 Batch 800 Loss 2.8515 Accuracy 0.2564\n",
            "Epoch 8 Batch 850 Loss 2.8490 Accuracy 0.2567\n",
            "Epoch 8 Batch 900 Loss 2.8499 Accuracy 0.2566\n",
            "Epoch 8 Batch 950 Loss 2.8493 Accuracy 0.2567\n",
            "Epoch 8 Batch 1000 Loss 2.8472 Accuracy 0.2564\n",
            "Epoch 8 Batch 1050 Loss 2.8481 Accuracy 0.2564\n",
            "Epoch 8 Batch 1100 Loss 2.8493 Accuracy 0.2564\n",
            "Epoch 8 Batch 1150 Loss 2.8511 Accuracy 0.2564\n",
            "Epoch 8 Batch 1200 Loss 2.8490 Accuracy 0.2566\n",
            "Epoch 8 Batch 1250 Loss 2.8494 Accuracy 0.2566\n",
            "Epoch 8 Batch 1300 Loss 2.8489 Accuracy 0.2568\n",
            "Epoch 8 Batch 1350 Loss 2.8500 Accuracy 0.2570\n",
            "Epoch 8 Batch 1400 Loss 2.8512 Accuracy 0.2568\n",
            "Epoch 8 Loss 2.8510 Accuracy 0.2569\n",
            "Time taken for 1 epoch: 992.5271427631378 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 2.9440 Accuracy 0.2378\n",
            "Epoch 9 Batch 50 Loss 2.7626 Accuracy 0.2588\n",
            "Epoch 9 Batch 100 Loss 2.7649 Accuracy 0.2580\n",
            "Epoch 9 Batch 150 Loss 2.7735 Accuracy 0.2616\n",
            "Epoch 9 Batch 200 Loss 2.7705 Accuracy 0.2623\n",
            "Epoch 9 Batch 250 Loss 2.7760 Accuracy 0.2615\n",
            "Epoch 9 Batch 300 Loss 2.7755 Accuracy 0.2615\n",
            "Epoch 9 Batch 350 Loss 2.7790 Accuracy 0.2609\n",
            "Epoch 9 Batch 400 Loss 2.7802 Accuracy 0.2605\n",
            "Epoch 9 Batch 450 Loss 2.7803 Accuracy 0.2606\n",
            "Epoch 9 Batch 500 Loss 2.7806 Accuracy 0.2603\n",
            "Epoch 9 Batch 550 Loss 2.7818 Accuracy 0.2609\n",
            "Epoch 9 Batch 600 Loss 2.7775 Accuracy 0.2612\n",
            "Epoch 9 Batch 650 Loss 2.7778 Accuracy 0.2610\n",
            "Epoch 9 Batch 700 Loss 2.7773 Accuracy 0.2611\n",
            "Epoch 9 Batch 750 Loss 2.7746 Accuracy 0.2611\n",
            "Epoch 9 Batch 800 Loss 2.7767 Accuracy 0.2610\n",
            "Epoch 9 Batch 850 Loss 2.7772 Accuracy 0.2609\n",
            "Epoch 9 Batch 900 Loss 2.7762 Accuracy 0.2611\n",
            "Epoch 9 Batch 950 Loss 2.7771 Accuracy 0.2609\n",
            "Epoch 9 Batch 1000 Loss 2.7758 Accuracy 0.2610\n",
            "Epoch 9 Batch 1050 Loss 2.7756 Accuracy 0.2609\n",
            "Epoch 9 Batch 1100 Loss 2.7753 Accuracy 0.2611\n",
            "Epoch 9 Batch 1150 Loss 2.7765 Accuracy 0.2608\n",
            "Epoch 9 Batch 1200 Loss 2.7772 Accuracy 0.2610\n",
            "Epoch 9 Batch 1250 Loss 2.7769 Accuracy 0.2609\n",
            "Epoch 9 Batch 1300 Loss 2.7778 Accuracy 0.2609\n",
            "Epoch 9 Batch 1350 Loss 2.7788 Accuracy 0.2611\n",
            "Epoch 9 Batch 1400 Loss 2.7797 Accuracy 0.2610\n",
            "Epoch 9 Loss 2.7798 Accuracy 0.2611\n",
            "Time taken for 1 epoch: 987.9047114849091 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 2.4507 Accuracy 0.2875\n",
            "Epoch 10 Batch 50 Loss 2.6841 Accuracy 0.2724\n",
            "Epoch 10 Batch 100 Loss 2.7153 Accuracy 0.2657\n",
            "Epoch 10 Batch 150 Loss 2.7162 Accuracy 0.2661\n",
            "Epoch 10 Batch 200 Loss 2.7210 Accuracy 0.2655\n",
            "Epoch 10 Batch 250 Loss 2.7241 Accuracy 0.2659\n",
            "Epoch 10 Batch 300 Loss 2.7197 Accuracy 0.2656\n",
            "Epoch 10 Batch 350 Loss 2.7158 Accuracy 0.2658\n",
            "Epoch 10 Batch 400 Loss 2.7168 Accuracy 0.2659\n",
            "Epoch 10 Batch 450 Loss 2.7177 Accuracy 0.2652\n",
            "Epoch 10 Batch 500 Loss 2.7196 Accuracy 0.2649\n",
            "Epoch 10 Batch 550 Loss 2.7165 Accuracy 0.2649\n",
            "Epoch 10 Batch 600 Loss 2.7194 Accuracy 0.2646\n",
            "Epoch 10 Batch 650 Loss 2.7206 Accuracy 0.2649\n",
            "Epoch 10 Batch 700 Loss 2.7205 Accuracy 0.2645\n",
            "Epoch 10 Batch 750 Loss 2.7214 Accuracy 0.2651\n",
            "Epoch 10 Batch 800 Loss 2.7199 Accuracy 0.2648\n",
            "Epoch 10 Batch 850 Loss 2.7201 Accuracy 0.2647\n",
            "Epoch 10 Batch 900 Loss 2.7169 Accuracy 0.2650\n",
            "Epoch 10 Batch 950 Loss 2.7154 Accuracy 0.2651\n",
            "Epoch 10 Batch 1000 Loss 2.7122 Accuracy 0.2650\n",
            "Epoch 10 Batch 1050 Loss 2.7143 Accuracy 0.2652\n",
            "Epoch 10 Batch 1100 Loss 2.7139 Accuracy 0.2652\n",
            "Epoch 10 Batch 1150 Loss 2.7138 Accuracy 0.2652\n",
            "Epoch 10 Batch 1200 Loss 2.7145 Accuracy 0.2652\n",
            "Epoch 10 Batch 1250 Loss 2.7131 Accuracy 0.2653\n",
            "Epoch 10 Batch 1300 Loss 2.7121 Accuracy 0.2655\n",
            "Epoch 10 Batch 1350 Loss 2.7121 Accuracy 0.2656\n",
            "Epoch 10 Batch 1400 Loss 2.7124 Accuracy 0.2655\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-4\n",
            "Epoch 10 Loss 2.7123 Accuracy 0.2655\n",
            "Time taken for 1 epoch: 984.9644286632538 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 2.3798 Accuracy 0.2525\n",
            "Epoch 11 Batch 50 Loss 2.6311 Accuracy 0.2624\n",
            "Epoch 11 Batch 100 Loss 2.6306 Accuracy 0.2663\n",
            "Epoch 11 Batch 150 Loss 2.6276 Accuracy 0.2690\n",
            "Epoch 11 Batch 200 Loss 2.6276 Accuracy 0.2698\n",
            "Epoch 11 Batch 250 Loss 2.6326 Accuracy 0.2699\n",
            "Epoch 11 Batch 300 Loss 2.6364 Accuracy 0.2700\n",
            "Epoch 11 Batch 350 Loss 2.6345 Accuracy 0.2695\n",
            "Epoch 11 Batch 400 Loss 2.6353 Accuracy 0.2691\n",
            "Epoch 11 Batch 450 Loss 2.6349 Accuracy 0.2689\n",
            "Epoch 11 Batch 500 Loss 2.6366 Accuracy 0.2688\n",
            "Epoch 11 Batch 550 Loss 2.6440 Accuracy 0.2683\n",
            "Epoch 11 Batch 600 Loss 2.6473 Accuracy 0.2680\n",
            "Epoch 11 Batch 650 Loss 2.6455 Accuracy 0.2685\n",
            "Epoch 11 Batch 700 Loss 2.6448 Accuracy 0.2685\n",
            "Epoch 11 Batch 750 Loss 2.6444 Accuracy 0.2685\n",
            "Epoch 11 Batch 800 Loss 2.6433 Accuracy 0.2684\n",
            "Epoch 11 Batch 850 Loss 2.6451 Accuracy 0.2680\n",
            "Epoch 11 Batch 900 Loss 2.6456 Accuracy 0.2684\n",
            "Epoch 11 Batch 950 Loss 2.6447 Accuracy 0.2685\n",
            "Epoch 11 Batch 1000 Loss 2.6450 Accuracy 0.2685\n",
            "Epoch 11 Batch 1050 Loss 2.6448 Accuracy 0.2685\n",
            "Epoch 11 Batch 1100 Loss 2.6434 Accuracy 0.2686\n",
            "Epoch 11 Batch 1150 Loss 2.6439 Accuracy 0.2686\n",
            "Epoch 11 Batch 1200 Loss 2.6442 Accuracy 0.2685\n",
            "Epoch 11 Batch 1250 Loss 2.6452 Accuracy 0.2684\n",
            "Epoch 11 Batch 1300 Loss 2.6445 Accuracy 0.2685\n",
            "Epoch 11 Batch 1350 Loss 2.6451 Accuracy 0.2684\n",
            "Epoch 11 Batch 1400 Loss 2.6463 Accuracy 0.2682\n",
            "Epoch 11 Loss 2.6466 Accuracy 0.2683\n",
            "Time taken for 1 epoch: 983.4395134449005 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 2.6733 Accuracy 0.2548\n",
            "Epoch 12 Batch 50 Loss 2.5822 Accuracy 0.2664\n",
            "Epoch 12 Batch 100 Loss 2.5844 Accuracy 0.2705\n",
            "Epoch 12 Batch 150 Loss 2.5740 Accuracy 0.2731\n",
            "Epoch 12 Batch 200 Loss 2.5811 Accuracy 0.2733\n",
            "Epoch 12 Batch 250 Loss 2.5843 Accuracy 0.2729\n",
            "Epoch 12 Batch 300 Loss 2.5752 Accuracy 0.2743\n",
            "Epoch 12 Batch 350 Loss 2.5767 Accuracy 0.2739\n",
            "Epoch 12 Batch 400 Loss 2.5789 Accuracy 0.2732\n",
            "Epoch 12 Batch 450 Loss 2.5758 Accuracy 0.2734\n",
            "Epoch 12 Batch 500 Loss 2.5760 Accuracy 0.2732\n",
            "Epoch 12 Batch 550 Loss 2.5765 Accuracy 0.2732\n",
            "Epoch 12 Batch 600 Loss 2.5756 Accuracy 0.2736\n",
            "Epoch 12 Batch 650 Loss 2.5761 Accuracy 0.2735\n",
            "Epoch 12 Batch 700 Loss 2.5766 Accuracy 0.2732\n",
            "Epoch 12 Batch 750 Loss 2.5772 Accuracy 0.2733\n",
            "Epoch 12 Batch 800 Loss 2.5777 Accuracy 0.2729\n",
            "Epoch 12 Batch 850 Loss 2.5785 Accuracy 0.2731\n",
            "Epoch 12 Batch 900 Loss 2.5779 Accuracy 0.2727\n",
            "Epoch 12 Batch 950 Loss 2.5790 Accuracy 0.2727\n",
            "Epoch 12 Batch 1000 Loss 2.5789 Accuracy 0.2725\n",
            "Epoch 12 Batch 1050 Loss 2.5799 Accuracy 0.2724\n",
            "Epoch 12 Batch 1100 Loss 2.5827 Accuracy 0.2723\n",
            "Epoch 12 Batch 1150 Loss 2.5831 Accuracy 0.2724\n",
            "Epoch 12 Batch 1200 Loss 2.5826 Accuracy 0.2725\n",
            "Epoch 12 Batch 1250 Loss 2.5843 Accuracy 0.2725\n",
            "Epoch 12 Batch 1300 Loss 2.5841 Accuracy 0.2723\n",
            "Epoch 12 Batch 1350 Loss 2.5853 Accuracy 0.2721\n",
            "Epoch 12 Batch 1400 Loss 2.5845 Accuracy 0.2722\n",
            "Epoch 12 Loss 2.5846 Accuracy 0.2722\n",
            "Time taken for 1 epoch: 988.9401478767395 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 2.7135 Accuracy 0.2604\n",
            "Epoch 13 Batch 50 Loss 2.4956 Accuracy 0.2718\n",
            "Epoch 13 Batch 100 Loss 2.5224 Accuracy 0.2740\n",
            "Epoch 13 Batch 150 Loss 2.5117 Accuracy 0.2753\n",
            "Epoch 13 Batch 200 Loss 2.5169 Accuracy 0.2748\n",
            "Epoch 13 Batch 250 Loss 2.5124 Accuracy 0.2743\n",
            "Epoch 13 Batch 300 Loss 2.5146 Accuracy 0.2749\n",
            "Epoch 13 Batch 350 Loss 2.5192 Accuracy 0.2758\n",
            "Epoch 13 Batch 400 Loss 2.5165 Accuracy 0.2758\n",
            "Epoch 13 Batch 450 Loss 2.5146 Accuracy 0.2762\n",
            "Epoch 13 Batch 500 Loss 2.5158 Accuracy 0.2761\n",
            "Epoch 13 Batch 550 Loss 2.5151 Accuracy 0.2762\n",
            "Epoch 13 Batch 600 Loss 2.5154 Accuracy 0.2765\n",
            "Epoch 13 Batch 650 Loss 2.5167 Accuracy 0.2769\n",
            "Epoch 13 Batch 700 Loss 2.5155 Accuracy 0.2770\n",
            "Epoch 13 Batch 750 Loss 2.5160 Accuracy 0.2767\n",
            "Epoch 13 Batch 800 Loss 2.5186 Accuracy 0.2763\n",
            "Epoch 13 Batch 850 Loss 2.5189 Accuracy 0.2763\n",
            "Epoch 13 Batch 900 Loss 2.5195 Accuracy 0.2764\n",
            "Epoch 13 Batch 950 Loss 2.5194 Accuracy 0.2763\n",
            "Epoch 13 Batch 1000 Loss 2.5214 Accuracy 0.2764\n",
            "Epoch 13 Batch 1050 Loss 2.5210 Accuracy 0.2765\n",
            "Epoch 13 Batch 1100 Loss 2.5221 Accuracy 0.2761\n",
            "Epoch 13 Batch 1150 Loss 2.5223 Accuracy 0.2763\n",
            "Epoch 13 Batch 1200 Loss 2.5227 Accuracy 0.2762\n",
            "Epoch 13 Batch 1250 Loss 2.5232 Accuracy 0.2760\n",
            "Epoch 13 Batch 1300 Loss 2.5243 Accuracy 0.2761\n",
            "Epoch 13 Batch 1350 Loss 2.5250 Accuracy 0.2759\n",
            "Epoch 13 Batch 1400 Loss 2.5269 Accuracy 0.2760\n",
            "Epoch 13 Loss 2.5267 Accuracy 0.2760\n",
            "Time taken for 1 epoch: 985.6766452789307 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 2.0807 Accuracy 0.2902\n",
            "Epoch 14 Batch 50 Loss 2.4402 Accuracy 0.2752\n",
            "Epoch 14 Batch 100 Loss 2.4321 Accuracy 0.2741\n",
            "Epoch 14 Batch 150 Loss 2.4400 Accuracy 0.2773\n",
            "Epoch 14 Batch 200 Loss 2.4448 Accuracy 0.2779\n",
            "Epoch 14 Batch 250 Loss 2.4486 Accuracy 0.2772\n",
            "Epoch 14 Batch 300 Loss 2.4456 Accuracy 0.2777\n",
            "Epoch 14 Batch 350 Loss 2.4518 Accuracy 0.2783\n",
            "Epoch 14 Batch 400 Loss 2.4553 Accuracy 0.2781\n",
            "Epoch 14 Batch 450 Loss 2.4621 Accuracy 0.2779\n",
            "Epoch 14 Batch 500 Loss 2.4612 Accuracy 0.2780\n",
            "Epoch 14 Batch 550 Loss 2.4618 Accuracy 0.2787\n",
            "Epoch 14 Batch 600 Loss 2.4617 Accuracy 0.2791\n",
            "Epoch 14 Batch 650 Loss 2.4630 Accuracy 0.2789\n",
            "Epoch 14 Batch 700 Loss 2.4636 Accuracy 0.2786\n",
            "Epoch 14 Batch 750 Loss 2.4629 Accuracy 0.2793\n",
            "Epoch 14 Batch 800 Loss 2.4650 Accuracy 0.2789\n",
            "Epoch 14 Batch 850 Loss 2.4653 Accuracy 0.2791\n",
            "Epoch 14 Batch 900 Loss 2.4636 Accuracy 0.2792\n",
            "Epoch 14 Batch 950 Loss 2.4677 Accuracy 0.2793\n",
            "Epoch 14 Batch 1000 Loss 2.4673 Accuracy 0.2794\n",
            "Epoch 14 Batch 1050 Loss 2.4664 Accuracy 0.2792\n",
            "Epoch 14 Batch 1100 Loss 2.4663 Accuracy 0.2791\n",
            "Epoch 14 Batch 1150 Loss 2.4666 Accuracy 0.2792\n",
            "Epoch 14 Batch 1200 Loss 2.4677 Accuracy 0.2793\n",
            "Epoch 14 Batch 1250 Loss 2.4685 Accuracy 0.2795\n",
            "Epoch 14 Batch 1300 Loss 2.4683 Accuracy 0.2797\n",
            "Epoch 14 Batch 1350 Loss 2.4687 Accuracy 0.2797\n",
            "Epoch 14 Batch 1400 Loss 2.4706 Accuracy 0.2796\n",
            "Epoch 14 Loss 2.4704 Accuracy 0.2796\n",
            "Time taken for 1 epoch: 981.349541425705 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 2.6086 Accuracy 0.2822\n",
            "Epoch 15 Batch 50 Loss 2.3881 Accuracy 0.2804\n",
            "Epoch 15 Batch 100 Loss 2.3979 Accuracy 0.2820\n",
            "Epoch 15 Batch 150 Loss 2.3894 Accuracy 0.2817\n",
            "Epoch 15 Batch 200 Loss 2.3959 Accuracy 0.2813\n",
            "Epoch 15 Batch 250 Loss 2.4042 Accuracy 0.2813\n",
            "Epoch 15 Batch 300 Loss 2.4043 Accuracy 0.2809\n",
            "Epoch 15 Batch 350 Loss 2.4021 Accuracy 0.2805\n",
            "Epoch 15 Batch 400 Loss 2.4051 Accuracy 0.2810\n",
            "Epoch 15 Batch 450 Loss 2.4097 Accuracy 0.2816\n",
            "Epoch 15 Batch 500 Loss 2.4114 Accuracy 0.2820\n",
            "Epoch 15 Batch 550 Loss 2.4118 Accuracy 0.2818\n",
            "Epoch 15 Batch 600 Loss 2.4132 Accuracy 0.2822\n",
            "Epoch 15 Batch 650 Loss 2.4127 Accuracy 0.2824\n",
            "Epoch 15 Batch 700 Loss 2.4116 Accuracy 0.2824\n",
            "Epoch 15 Batch 750 Loss 2.4101 Accuracy 0.2824\n",
            "Epoch 15 Batch 800 Loss 2.4107 Accuracy 0.2828\n",
            "Epoch 15 Batch 850 Loss 2.4120 Accuracy 0.2829\n",
            "Epoch 15 Batch 900 Loss 2.4139 Accuracy 0.2830\n",
            "Epoch 15 Batch 950 Loss 2.4165 Accuracy 0.2831\n",
            "Epoch 15 Batch 1000 Loss 2.4142 Accuracy 0.2833\n",
            "Epoch 15 Batch 1050 Loss 2.4139 Accuracy 0.2831\n",
            "Epoch 15 Batch 1100 Loss 2.4130 Accuracy 0.2835\n",
            "Epoch 15 Batch 1150 Loss 2.4141 Accuracy 0.2835\n",
            "Epoch 15 Batch 1200 Loss 2.4148 Accuracy 0.2832\n",
            "Epoch 15 Batch 1250 Loss 2.4160 Accuracy 0.2832\n",
            "Epoch 15 Batch 1300 Loss 2.4171 Accuracy 0.2831\n",
            "Epoch 15 Batch 1350 Loss 2.4181 Accuracy 0.2829\n",
            "Epoch 15 Batch 1400 Loss 2.4199 Accuracy 0.2827\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-5\n",
            "Epoch 15 Loss 2.4199 Accuracy 0.2827\n",
            "Time taken for 1 epoch: 982.8303458690643 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 2.5205 Accuracy 0.2737\n",
            "Epoch 16 Batch 50 Loss 2.3612 Accuracy 0.2834\n",
            "Epoch 16 Batch 100 Loss 2.3613 Accuracy 0.2831\n",
            "Epoch 16 Batch 150 Loss 2.3437 Accuracy 0.2845\n",
            "Epoch 16 Batch 200 Loss 2.3464 Accuracy 0.2852\n",
            "Epoch 16 Batch 250 Loss 2.3524 Accuracy 0.2848\n",
            "Epoch 16 Batch 300 Loss 2.3572 Accuracy 0.2836\n",
            "Epoch 16 Batch 350 Loss 2.3524 Accuracy 0.2845\n",
            "Epoch 16 Batch 400 Loss 2.3538 Accuracy 0.2848\n",
            "Epoch 16 Batch 450 Loss 2.3556 Accuracy 0.2851\n",
            "Epoch 16 Batch 500 Loss 2.3577 Accuracy 0.2854\n",
            "Epoch 16 Batch 550 Loss 2.3575 Accuracy 0.2848\n",
            "Epoch 16 Batch 600 Loss 2.3586 Accuracy 0.2849\n",
            "Epoch 16 Batch 650 Loss 2.3591 Accuracy 0.2855\n",
            "Epoch 16 Batch 700 Loss 2.3585 Accuracy 0.2856\n",
            "Epoch 16 Batch 750 Loss 2.3582 Accuracy 0.2855\n",
            "Epoch 16 Batch 800 Loss 2.3596 Accuracy 0.2857\n",
            "Epoch 16 Batch 850 Loss 2.3607 Accuracy 0.2856\n",
            "Epoch 16 Batch 900 Loss 2.3598 Accuracy 0.2858\n",
            "Epoch 16 Batch 950 Loss 2.3606 Accuracy 0.2858\n",
            "Epoch 16 Batch 1000 Loss 2.3596 Accuracy 0.2858\n",
            "Epoch 16 Batch 1050 Loss 2.3601 Accuracy 0.2856\n",
            "Epoch 16 Batch 1100 Loss 2.3627 Accuracy 0.2856\n",
            "Epoch 16 Batch 1150 Loss 2.3643 Accuracy 0.2854\n",
            "Epoch 16 Batch 1200 Loss 2.3657 Accuracy 0.2852\n",
            "Epoch 16 Batch 1250 Loss 2.3671 Accuracy 0.2854\n",
            "Epoch 16 Batch 1300 Loss 2.3674 Accuracy 0.2855\n",
            "Epoch 16 Batch 1350 Loss 2.3671 Accuracy 0.2858\n",
            "Epoch 16 Batch 1400 Loss 2.3677 Accuracy 0.2859\n",
            "Epoch 16 Loss 2.3675 Accuracy 0.2859\n",
            "Time taken for 1 epoch: 989.3410587310791 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 2.4392 Accuracy 0.2652\n",
            "Epoch 17 Batch 50 Loss 2.2788 Accuracy 0.2884\n",
            "Epoch 17 Batch 100 Loss 2.2860 Accuracy 0.2907\n",
            "Epoch 17 Batch 150 Loss 2.2967 Accuracy 0.2882\n",
            "Epoch 17 Batch 200 Loss 2.3044 Accuracy 0.2884\n",
            "Epoch 17 Batch 250 Loss 2.3077 Accuracy 0.2871\n",
            "Epoch 17 Batch 300 Loss 2.3145 Accuracy 0.2880\n",
            "Epoch 17 Batch 350 Loss 2.3065 Accuracy 0.2876\n",
            "Epoch 17 Batch 400 Loss 2.3068 Accuracy 0.2866\n",
            "Epoch 17 Batch 450 Loss 2.3063 Accuracy 0.2873\n",
            "Epoch 17 Batch 500 Loss 2.3072 Accuracy 0.2877\n",
            "Epoch 17 Batch 550 Loss 2.3079 Accuracy 0.2880\n",
            "Epoch 17 Batch 600 Loss 2.3109 Accuracy 0.2884\n",
            "Epoch 17 Batch 650 Loss 2.3122 Accuracy 0.2885\n",
            "Epoch 17 Batch 700 Loss 2.3131 Accuracy 0.2885\n",
            "Epoch 17 Batch 750 Loss 2.3150 Accuracy 0.2888\n",
            "Epoch 17 Batch 800 Loss 2.3142 Accuracy 0.2887\n",
            "Epoch 17 Batch 850 Loss 2.3135 Accuracy 0.2885\n",
            "Epoch 17 Batch 900 Loss 2.3141 Accuracy 0.2890\n",
            "Epoch 17 Batch 950 Loss 2.3140 Accuracy 0.2891\n",
            "Epoch 17 Batch 1000 Loss 2.3148 Accuracy 0.2889\n",
            "Epoch 17 Batch 1050 Loss 2.3160 Accuracy 0.2887\n",
            "Epoch 17 Batch 1100 Loss 2.3156 Accuracy 0.2886\n",
            "Epoch 17 Batch 1150 Loss 2.3153 Accuracy 0.2887\n",
            "Epoch 17 Batch 1200 Loss 2.3156 Accuracy 0.2887\n",
            "Epoch 17 Batch 1250 Loss 2.3167 Accuracy 0.2885\n",
            "Epoch 17 Batch 1300 Loss 2.3160 Accuracy 0.2887\n",
            "Epoch 17 Batch 1350 Loss 2.3176 Accuracy 0.2886\n",
            "Epoch 17 Batch 1400 Loss 2.3178 Accuracy 0.2887\n",
            "Epoch 17 Loss 2.3178 Accuracy 0.2888\n",
            "Time taken for 1 epoch: 991.5647130012512 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 2.0491 Accuracy 0.2676\n",
            "Epoch 18 Batch 50 Loss 2.2425 Accuracy 0.2910\n",
            "Epoch 18 Batch 100 Loss 2.2501 Accuracy 0.2861\n",
            "Epoch 18 Batch 150 Loss 2.2491 Accuracy 0.2883\n",
            "Epoch 18 Batch 200 Loss 2.2467 Accuracy 0.2887\n",
            "Epoch 18 Batch 250 Loss 2.2517 Accuracy 0.2887\n",
            "Epoch 18 Batch 300 Loss 2.2560 Accuracy 0.2892\n",
            "Epoch 18 Batch 350 Loss 2.2626 Accuracy 0.2894\n",
            "Epoch 18 Batch 400 Loss 2.2662 Accuracy 0.2897\n",
            "Epoch 18 Batch 450 Loss 2.2670 Accuracy 0.2897\n",
            "Epoch 18 Batch 500 Loss 2.2611 Accuracy 0.2904\n",
            "Epoch 18 Batch 550 Loss 2.2611 Accuracy 0.2908\n",
            "Epoch 18 Batch 600 Loss 2.2627 Accuracy 0.2907\n",
            "Epoch 18 Batch 650 Loss 2.2635 Accuracy 0.2910\n",
            "Epoch 18 Batch 700 Loss 2.2633 Accuracy 0.2909\n",
            "Epoch 18 Batch 750 Loss 2.2641 Accuracy 0.2910\n",
            "Epoch 18 Batch 800 Loss 2.2652 Accuracy 0.2913\n",
            "Epoch 18 Batch 850 Loss 2.2660 Accuracy 0.2911\n",
            "Epoch 18 Batch 900 Loss 2.2678 Accuracy 0.2909\n",
            "Epoch 18 Batch 950 Loss 2.2668 Accuracy 0.2909\n",
            "Epoch 18 Batch 1000 Loss 2.2677 Accuracy 0.2910\n",
            "Epoch 18 Batch 1050 Loss 2.2693 Accuracy 0.2909\n",
            "Epoch 18 Batch 1100 Loss 2.2693 Accuracy 0.2907\n",
            "Epoch 18 Batch 1150 Loss 2.2692 Accuracy 0.2908\n",
            "Epoch 18 Batch 1200 Loss 2.2697 Accuracy 0.2909\n",
            "Epoch 18 Batch 1250 Loss 2.2705 Accuracy 0.2910\n",
            "Epoch 18 Batch 1300 Loss 2.2707 Accuracy 0.2914\n",
            "Epoch 18 Batch 1350 Loss 2.2701 Accuracy 0.2915\n",
            "Epoch 18 Batch 1400 Loss 2.2708 Accuracy 0.2913\n",
            "Epoch 18 Loss 2.2711 Accuracy 0.2913\n",
            "Time taken for 1 epoch: 987.0150997638702 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 2.5461 Accuracy 0.2630\n",
            "Epoch 19 Batch 50 Loss 2.2157 Accuracy 0.2897\n",
            "Epoch 19 Batch 100 Loss 2.2307 Accuracy 0.2924\n",
            "Epoch 19 Batch 150 Loss 2.2148 Accuracy 0.2914\n",
            "Epoch 19 Batch 200 Loss 2.2250 Accuracy 0.2916\n",
            "Epoch 19 Batch 250 Loss 2.2216 Accuracy 0.2917\n",
            "Epoch 19 Batch 300 Loss 2.2164 Accuracy 0.2928\n",
            "Epoch 19 Batch 350 Loss 2.2187 Accuracy 0.2923\n",
            "Epoch 19 Batch 400 Loss 2.2196 Accuracy 0.2924\n",
            "Epoch 19 Batch 450 Loss 2.2199 Accuracy 0.2925\n",
            "Epoch 19 Batch 500 Loss 2.2159 Accuracy 0.2929\n",
            "Epoch 19 Batch 550 Loss 2.2170 Accuracy 0.2931\n",
            "Epoch 19 Batch 600 Loss 2.2191 Accuracy 0.2931\n",
            "Epoch 19 Batch 650 Loss 2.2165 Accuracy 0.2933\n",
            "Epoch 19 Batch 700 Loss 2.2190 Accuracy 0.2930\n",
            "Epoch 19 Batch 750 Loss 2.2179 Accuracy 0.2928\n",
            "Epoch 19 Batch 800 Loss 2.2196 Accuracy 0.2928\n",
            "Epoch 19 Batch 850 Loss 2.2212 Accuracy 0.2932\n",
            "Epoch 19 Batch 900 Loss 2.2222 Accuracy 0.2933\n",
            "Epoch 19 Batch 950 Loss 2.2237 Accuracy 0.2934\n",
            "Epoch 19 Batch 1000 Loss 2.2233 Accuracy 0.2935\n",
            "Epoch 19 Batch 1050 Loss 2.2230 Accuracy 0.2937\n",
            "Epoch 19 Batch 1100 Loss 2.2230 Accuracy 0.2939\n",
            "Epoch 19 Batch 1150 Loss 2.2233 Accuracy 0.2943\n",
            "Epoch 19 Batch 1200 Loss 2.2245 Accuracy 0.2940\n",
            "Epoch 19 Batch 1250 Loss 2.2245 Accuracy 0.2943\n",
            "Epoch 19 Batch 1300 Loss 2.2258 Accuracy 0.2940\n",
            "Epoch 19 Batch 1350 Loss 2.2282 Accuracy 0.2941\n",
            "Epoch 19 Batch 1400 Loss 2.2277 Accuracy 0.2941\n",
            "Epoch 19 Loss 2.2275 Accuracy 0.2941\n",
            "Time taken for 1 epoch: 984.813399553299 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 2.1882 Accuracy 0.3236\n",
            "Epoch 20 Batch 50 Loss 2.1400 Accuracy 0.3042\n",
            "Epoch 20 Batch 100 Loss 2.1371 Accuracy 0.2988\n",
            "Epoch 20 Batch 150 Loss 2.1532 Accuracy 0.3006\n",
            "Epoch 20 Batch 200 Loss 2.1481 Accuracy 0.3000\n",
            "Epoch 20 Batch 250 Loss 2.1523 Accuracy 0.2986\n",
            "Epoch 20 Batch 300 Loss 2.1562 Accuracy 0.2984\n",
            "Epoch 20 Batch 350 Loss 2.1619 Accuracy 0.2979\n",
            "Epoch 20 Batch 400 Loss 2.1622 Accuracy 0.2987\n",
            "Epoch 20 Batch 450 Loss 2.1708 Accuracy 0.2973\n",
            "Epoch 20 Batch 500 Loss 2.1703 Accuracy 0.2973\n",
            "Epoch 20 Batch 550 Loss 2.1721 Accuracy 0.2976\n",
            "Epoch 20 Batch 600 Loss 2.1736 Accuracy 0.2972\n",
            "Epoch 20 Batch 650 Loss 2.1751 Accuracy 0.2970\n",
            "Epoch 20 Batch 700 Loss 2.1745 Accuracy 0.2978\n",
            "Epoch 20 Batch 750 Loss 2.1743 Accuracy 0.2978\n",
            "Epoch 20 Batch 800 Loss 2.1749 Accuracy 0.2976\n",
            "Epoch 20 Batch 850 Loss 2.1750 Accuracy 0.2973\n",
            "Epoch 20 Batch 900 Loss 2.1777 Accuracy 0.2971\n",
            "Epoch 20 Batch 950 Loss 2.1786 Accuracy 0.2969\n",
            "Epoch 20 Batch 1000 Loss 2.1801 Accuracy 0.2971\n",
            "Epoch 20 Batch 1050 Loss 2.1824 Accuracy 0.2969\n",
            "Epoch 20 Batch 1100 Loss 2.1840 Accuracy 0.2964\n",
            "Epoch 20 Batch 1150 Loss 2.1846 Accuracy 0.2966\n",
            "Epoch 20 Batch 1200 Loss 2.1844 Accuracy 0.2967\n",
            "Epoch 20 Batch 1250 Loss 2.1855 Accuracy 0.2967\n",
            "Epoch 20 Batch 1300 Loss 2.1860 Accuracy 0.2966\n",
            "Epoch 20 Batch 1350 Loss 2.1864 Accuracy 0.2967\n",
            "Epoch 20 Batch 1400 Loss 2.1870 Accuracy 0.2967\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-6\n",
            "Epoch 20 Loss 2.1869 Accuracy 0.2967\n",
            "Time taken for 1 epoch: 995.5457961559296 secs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
        "                                                train_loss.result(),\n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5buvMlnvyrFm"
      },
      "outputs": [],
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_pt.vocab_size]\n",
        "  end_token = [tokenizer_pt.vocab_size + 1]\n",
        "\n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [tokenizer_en.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer_en.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amDqKFOYOp6z"
      },
      "outputs": [],
      "source": [
        "sentence=\"este é um problema que temos que resolver.\"\n",
        "\n",
        "result, attention_weights = evaluate(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUYysnkIR_-V",
        "outputId": "2309b264-a590-4703-c40b-d43a21d52eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(21,), dtype=int32, numpy=\n",
              "array([8087,   16,   13,    7,  328,   10,   14,  132,    5,  966,    3,\n",
              "       7948, 7877, 7946,  302,   14,  132,    5,  966,   19,    2],\n",
              "      dtype=int32)>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmYL0oqFOp_A",
        "outputId": "b660ab99-1dcf-4228-a99c-e6050bf411dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['decoder_layer1_block1', 'decoder_layer1_block2', 'decoder_layer2_block1', 'decoder_layer2_block2', 'decoder_layer3_block1', 'decoder_layer3_block2', 'decoder_layer4_block1', 'decoder_layer4_block2'])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_weights.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU2_yG_vBGza"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer_en.decode([i for i in result\n",
        "                                            if i < tokenizer_en.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Ws0EN9RaLY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsxrAlvFG8SZ",
        "outputId": "fe922ea6-140b-4490-ce51-71961db5c281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: este é um problema que temos que resolver.\n",
            "Predicted translation: this is a problem that we need to solve the u.s. we need to solve it .\n",
            "Real translation: this is a problem we have to solve .\n"
          ]
        }
      ],
      "source": [
        "translate(\"este é um problema que temos que resolver.\")\n",
        "print (\"Real translation: this is a problem we have to solve .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EH5y_aqI4t1",
        "outputId": "1b6270be-a0d5-4ded-d8b6-f983e4e8a7d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: os meus vizinhos ouviram sobre esta ideia.\n",
            "Predicted translation: my neighbors heard about this idea .\n",
            "Real translation: and my neighboring homes heard about this idea .\n"
          ]
        }
      ],
      "source": [
        "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
        "print (\"Real translation: and my neighboring homes heard about this idea .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-hVCTSUMlkb",
        "outputId": "02641125-71ac-413b-da86-faeb9256c7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
            "Predicted translation: so i 'm going to play very quickly share with you some of some some of some bad stories that would happen .\n",
            "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
          ]
        }
      ],
      "source": [
        "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
        "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-kFyiOLH0xg",
        "outputId": "955695c3-e5d5-44a4-bf5c-a7753bd22adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: este é o primeiro livro que eu fiz.\n",
            "Predicted translation: this is the first book i did .\n",
            "Real translation: this is the first book i've ever done.\n"
          ]
        }
      ],
      "source": [
        "translate(\"este é o primeiro livro que eu fiz.\")\n",
        "print (\"Real translation: this is the first book i've ever done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooPd1XHTG6Wy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "s_qNSzzyaCbD"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}